{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vgwxvgVVY2Of",
        "outputId": "4ab64409-c4e3-49a4-bb03-85e66c3f2b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "TensorFlow: 2.19.0\n",
            "Available physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Minimal environment check (no pip installs)\n",
        "import sys, tensorflow as tf, os\n",
        "print(\"Python:\", sys.version.splitlines()[0])\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Available physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "# Show nvidia-smi if available (optional)\n",
        "os.system(\"nvidia-smi || echo 'nvidia-smi not available in this runtime'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()   # choose kaggle.json when prompt appears (do this step)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "v036XlahZLy-",
        "outputId": "8a70f7ac-c6fc-4d10-8af2-88ed66da6e04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a54446a-493e-4436-b953-d2e5db4a510f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a54446a-493e-4436-b953-d2e5db4a510f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ruthwikreddy1605\",\"key\":\"5ccc8c17869616088ff3b1fb73ef95e0\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "omTlaXCuoRCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "GFy3C6BMZTS0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloads the dataset into /content/ultrasound_project and unzips\n",
        "!mkdir -p /content/ultrasound_project\n",
        "%cd /content/ultrasound_project\n",
        "!kaggle datasets download -d orvile/bus-uclm-breast-ultrasound-dataset -p /content/ultrasound_project --unzip\n",
        "!ls -la\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZqAJUNApZWhF",
        "outputId": "8fc730f8-e1c3-407d-a270-168e404cd179"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ultrasound_project\n",
            "Dataset URL: https://www.kaggle.com/datasets/orvile/bus-uclm-breast-ultrasound-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading bus-uclm-breast-ultrasound-dataset.zip to /content/ultrasound_project\n",
            " 95% 608M/642M [00:04<00:00, 114MB/s]\n",
            "100% 642M/642M [00:06<00:00, 104MB/s]\n",
            "total 16\n",
            "drwxr-xr-x 4 root root 4096 Nov 22 13:55  .\n",
            "drwxr-xr-x 1 root root 4096 Nov 22 13:54  ..\n",
            "drwxr-xr-x 3 root root 4096 Nov 22 13:55 'BUS-UCLM Breast ultrasound lesion segmentation dataset'\n",
            "drwxr-xr-x 5 root root 4096 Nov 22 13:55  bus_uclm_separated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for root, dirs, files in os.walk(\"/content/ultrasound_project\", topdown=True):\n",
        "    level = root.replace(\"/content/ultrasound_project\", \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * (level)\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    if level==1:\n",
        "        print(\"   subfolders:\", dirs)\n",
        "    if level>1:\n",
        "        # limit printing files for brevity\n",
        "        print(f\"{indent}  {len(files)} files (showing up to 5):\", files[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "N9pWbU6XZZL4",
        "outputId": "4033cdd8-2951-43d3-8a29-493873d1d585"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ultrasound_project/\n",
            "  bus_uclm_separated/\n",
            "   subfolders: ['benign', 'malign', 'normal']\n",
            "    benign/\n",
            "      174 files (showing up to 5): ['PLBA_019.png', 'ALWI_002.png', 'ORPE_001.png', 'TOCI_020.png', 'HESN_005.png']\n",
            "    malign/\n",
            "      90 files (showing up to 5): ['FLBA_005.png', 'SIBA_003.png', 'CODE_006.png', 'CHVI_001.png', 'ELCO_006.png']\n",
            "    normal/\n",
            "      419 files (showing up to 5): ['UNCU_009.png', 'HESN_011.png', 'TOCI_019.png', 'ORPE_010.png', 'CHSP_001.png']\n",
            "  BUS-UCLM Breast ultrasound lesion segmentation dataset/\n",
            "   subfolders: ['BUS-UCLM Breast ultrasound lesion segmentation dataset']\n",
            "    BUS-UCLM Breast ultrasound lesion segmentation dataset/\n",
            "      0 files (showing up to 5): []\n",
            "      BUS-UCLM/\n",
            "        1 files (showing up to 5): ['INFO.csv']\n",
            "        images/\n",
            "          683 files (showing up to 5): ['FLBA_005.png', 'UNCU_009.png', 'HESN_011.png', 'TOCI_019.png', 'ORPE_010.png']\n",
            "        masks/\n",
            "          683 files (showing up to 5): ['FLBA_005.png', 'UNCU_009.png', 'HESN_011.png', 'TOCI_019.png', 'ORPE_010.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Contents of /content:\")\n",
        "print(os.listdir(\"/content\"))\n",
        "\n",
        "print(\"\\nContents of /content/ultrasound_project:\")\n",
        "print(os.listdir(\"/content/ultrasound_project\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g5OUtj3qZh9e",
        "outputId": "4b1c258f-02c1-42da-b91f-f74ebb66e086"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content:\n",
            "['.config', 'drive', 'ultrasound_project', 'sample_data']\n",
            "\n",
            "Contents of /content/ultrasound_project:\n",
            "['bus_uclm_separated', 'BUS-UCLM Breast ultrasound lesion segmentation dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/ultrasound_project/BUS\"\n"
      ],
      "metadata": {
        "id": "dV66wHbkZqcq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Folder 1 contents:\")\n",
        "print(os.listdir(\"/content/ultrasound_project/BUS-UCLM Breast ultrasound lesion segmentation dataset\"))\n",
        "\n",
        "print(\"\\nFolder 2 contents:\")\n",
        "print(os.listdir(\"/content/ultrasound_project/bus_uclm_separated\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9Y6JVBOWZtGF",
        "outputId": "ab373685-90da-4af8-ea2d-6d5dbf2dc841"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 1 contents:\n",
            "['BUS-UCLM Breast ultrasound lesion segmentation dataset']\n",
            "\n",
            "Folder 2 contents:\n",
            "['benign', 'malign', 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== REPLACE previous dataset cell with this one =====\n",
        "import tensorflow as tf, os, random, numpy as np\n",
        "from glob import glob\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "DATA_DIR = \"/content/ultrasound_project/bus_uclm_separated\"  # your folder\n",
        "\n",
        "# allowed image extensions (filter out non-image files)\n",
        "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\", \".tif\")\n",
        "\n",
        "classes = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "# collect file paths and labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "for idx, cls in enumerate(classes):\n",
        "    folder = os.path.join(DATA_DIR, cls)\n",
        "    all_files = sorted(os.listdir(folder))\n",
        "    # build only valid image files\n",
        "    for fn in all_files:\n",
        "        if fn.lower().endswith(IMG_EXTS):\n",
        "            file_paths.append(os.path.join(folder, fn))\n",
        "            labels.append(idx)\n",
        "\n",
        "print(f\"Found {len(file_paths)} image files across {len(classes)} classes.\")\n",
        "\n",
        "# shuffle together (deterministic seed)\n",
        "data = list(zip(file_paths, labels))\n",
        "random.Random(42).shuffle(data)\n",
        "file_paths, labels = zip(*data)\n",
        "file_paths = list(file_paths)\n",
        "labels = list(labels)\n",
        "\n",
        "# train/val/test split indices\n",
        "n = len(file_paths)\n",
        "train_end = int(0.8 * n)\n",
        "val_end = int(0.9 * n)\n",
        "\n",
        "train_files = file_paths[:train_end]\n",
        "train_labels = labels[:train_end]\n",
        "val_files = file_paths[train_end:val_end]\n",
        "val_labels = labels[train_end:val_end]\n",
        "test_files = file_paths[val_end:]\n",
        "test_labels = labels[val_end:]\n",
        "\n",
        "print(\"Split sizes -> train:\", len(train_files), \"val:\", len(val_files), \"test:\", len(test_files))\n",
        "\n",
        "# helper preprocess\n",
        "def preprocess_image(path):\n",
        "    # path is a tf.string scalar path\n",
        "    image_bytes = tf.io.read_file(path)\n",
        "    # use decode_image which handles png/jpg and returns rank-3 tensor [H,W,C]\n",
        "    image = tf.io.decode_image(image_bytes, channels=1, expand_animations=False)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # 0..1\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = tf.image.grayscale_to_rgb(image)  # make 3 channels\n",
        "    return image\n",
        "\n",
        "def make_ds(file_list, label_list, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    files_tf = tf.constant(file_list)\n",
        "    labels_tf = tf.constant(label_list, dtype=tf.int32)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((files_tf, labels_tf))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(file_list), seed=42)\n",
        "    def map_fn(path, label):\n",
        "        img = preprocess_image(path)\n",
        "        label_onehot = tf.one_hot(label, depth=len(classes))\n",
        "        return img, label_onehot\n",
        "    ds = ds.map(map_fn, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_ds(train_files, train_labels)\n",
        "val_ds   = make_ds(val_files, val_labels, shuffle=False)\n",
        "test_ds  = make_ds(test_files, test_labels, shuffle=False)\n",
        "\n",
        "# quick sanity check: show one sample shape and a small batch shape\n",
        "for imgs, labs in train_ds.take(1):\n",
        "    print(\"Batch images shape:\", imgs.shape)\n",
        "    print(\"Batch labels shape:\", labs.shape)\n",
        "    # show one image stats\n",
        "    print(\"Sample image min/max:\", tf.reduce_min(imgs[0]).numpy(), tf.reduce_max(imgs[0]).numpy())\n",
        "\n",
        "print(\"Datasets ready: train_ds, val_ds, test_ds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3x0gC8m6Z5MG",
        "outputId": "dc36218a-e3bd-44a5-936e-f0b428821868"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['benign', 'malign', 'normal']\n",
            "Found 683 image files across 3 classes.\n",
            "Split sizes -> train: 546 val: 68 test: 69\n",
            "Batch images shape: (32, 224, 224, 3)\n",
            "Batch labels shape: (32, 3)\n",
            "Sample image min/max: 0.024691427 0.9871005\n",
            "Datasets ready: train_ds, val_ds, test_ds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: GPU check, mixed precision, imports\n",
        "import tensorflow as tf, os, math\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Enable mixed precision for speed on GPU\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    mixed_precision.set_global_policy('mixed_float16')\n",
        "    print(\"Mixed precision enabled (policy):\", mixed_precision.global_policy())\n",
        "except Exception as e:\n",
        "    print(\"Mixed precision not enabled:\", e)\n",
        "\n",
        "# Useful globals (should match dataset)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = len(classes)  # uses classes from your dataset cell\n",
        "PAPER_PATH = \"/mnt/data/952 Manuscript (1).pdf\"   # your uploaded manuscript\n",
        "print(\"Classes:\", classes)\n",
        "print(\"PAPER_PATH:\", PAPER_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OghXQzxnaGz_",
        "outputId": "16907084-542b-4418-9efc-85a3d80c4789"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Mixed precision enabled (policy): <DTypePolicy \"mixed_float16\">\n",
            "Classes: ['benign', 'malign', 'normal']\n",
            "PAPER_PATH: /mnt/data/952 Manuscript (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: Build hybrid model (Transformer encoder + RNN fusion)\n",
        "from tensorflow.keras import Model, Input\n",
        "\n",
        "def build_hybrid_model(img_size=IMG_SIZE, patch_size=16, embed_dim=128, num_heads=4,\n",
        "                       mlp_dim=256, transformer_blocks=3, rnn_units=256, num_classes=NUM_CLASSES):\n",
        "    # Input\n",
        "    inp = Input(shape=(img_size, img_size, 3), name=\"image_input\")\n",
        "    # Patch embedding via Conv2D\n",
        "    x = layers.Conv2D(embed_dim, kernel_size=patch_size, strides=patch_size, padding='valid', name=\"patch_conv\")(inp)\n",
        "    x = layers.Reshape((-1, embed_dim), name=\"patch_reshape\")(x)  # (patches, embed_dim)\n",
        "\n",
        "    # Transformer encoder stack\n",
        "    for i in range(transformer_blocks):\n",
        "        # Layer norm + MHA + residual\n",
        "        y = layers.LayerNormalization(epsilon=1e-6, name=f\"ln1_{i}\")(x)\n",
        "        attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name=f\"mha_{i}\")(y, y)\n",
        "        x = layers.Add(name=f\"res1_{i}\")([x, attn])\n",
        "        # MLP block\n",
        "        z = layers.LayerNormalization(epsilon=1e-6, name=f\"ln2_{i}\")(x)\n",
        "        z = layers.Dense(mlp_dim, activation='gelu', name=f\"mlp1_{i}\")(z)\n",
        "        z = layers.Dropout(0.1, name=f\"drop_{i}\")(z)\n",
        "        z = layers.Dense(embed_dim, name=f\"mlp2_{i}\")(z)\n",
        "        x = layers.Add(name=f\"res2_{i}\")([x, z])\n",
        "\n",
        "    # Global context per image (C_t)\n",
        "    C_t = layers.GlobalAveragePooling1D(name=\"global_pool\")(x)   # shape (embed_dim,)\n",
        "\n",
        "    # Project context to rnn space\n",
        "    projC = layers.Dense(rnn_units, name=\"projectC\")(C_t)        # (rnn_units,)\n",
        "    # Make a single-step sequence for GRU\n",
        "    H_in = layers.Reshape((1, rnn_units), name=\"rnn_input\")(projC)\n",
        "    H_t = layers.GRU(rnn_units, return_sequences=False, name=\"gru\")(H_in)  # (rnn_units,)\n",
        "\n",
        "    # Learnable scalar alpha: use a dense->sigmoid to get a scalar per batch\n",
        "    alpha_raw = layers.Dense(1, activation='sigmoid', name=\"fusion_alpha_dense\")(layers.Concatenate()([H_t, projC]))\n",
        "    alpha = layers.Flatten(name=\"fusion_alpha\")(alpha_raw)  # shape (batch,)\n",
        "\n",
        "    # Fuse: F_t = alpha * H_t + (1-alpha) * projC\n",
        "    # Expand alpha to match dims\n",
        "    alpha_exp = layers.Lambda(lambda z: tf.expand_dims(z, axis=-1), name=\"alpha_expand\")(alpha)\n",
        "    F_t = layers.Lambda(lambda z: z[0]*z[1] + (1.0 - z[0])*z[2], name=\"fusion\")([alpha_exp, H_t, projC])\n",
        "\n",
        "    # Classification head\n",
        "    out = layers.LayerNormalization(name=\"head_ln\")(F_t)\n",
        "    out = layers.Dense(256, activation='relu', name=\"head_fc1\")(out)\n",
        "    out = layers.Dropout(0.25)(out)\n",
        "    # If using mixed_precision, final logits should be float32 for numeric stability\n",
        "    out = layers.Dense(num_classes, name=\"logits\")(out)\n",
        "    out = layers.Activation('softmax', dtype='float32', name=\"softmax_out\")(out)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out, name=\"HybridTransRNN\")\n",
        "    return model\n",
        "\n",
        "# Build and compile\n",
        "model = build_hybrid_model()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "# If mixed precision is used, wrap optimizer for loss scaling automatically by Keras\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1873
        },
        "id": "89sUB_CAaL6G",
        "outputId": "923da7a8-4cb2-4c29-b7e7-3f637e8c46d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"HybridTransRNN\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"HybridTransRNN\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ patch_conv (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m98,432\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ patch_reshape       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ patch_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln1_0               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ patch_reshape[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha_0               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m263,808\u001b[0m │ ln1_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ ln1_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res1_0 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ patch_reshape[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ mha_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln2_0               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ res1_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp1_0 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │     \u001b[38;5;34m33,024\u001b[0m │ ln2_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ drop_0 (\u001b[38;5;33mDropout\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ mlp1_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp2_0 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ drop_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res2_0 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ res1_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ mlp2_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln1_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ res2_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m263,808\u001b[0m │ ln1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ ln1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res1_1 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ res2_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ mha_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln2_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ res1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp1_1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │     \u001b[38;5;34m33,024\u001b[0m │ ln2_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ drop_1 (\u001b[38;5;33mDropout\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ mlp1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp2_1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ drop_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res2_1 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ res1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ mlp2_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln1_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ res2_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m263,808\u001b[0m │ ln1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ ln1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res1_2 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ res2_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ mha_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln2_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ res1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp1_2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │     \u001b[38;5;34m33,024\u001b[0m │ ln2_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ drop_2 (\u001b[38;5;33mDropout\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ mlp1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp2_2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,896\u001b[0m │ drop_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res2_2 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ res1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ mlp2_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ res2_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ projectC (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m33,024\u001b[0m │ global_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rnn_input (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ projectC[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m394,752\u001b[0m │ rnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ projectC[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_alpha_dense  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m513\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_alpha        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ fusion_alpha_den… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ alpha_expand        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ fusion_alpha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ alpha_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ projectC[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ head_ln             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ fusion[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ head_fc1 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m65,792\u001b[0m │ head_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ head_fc1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ logits (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │        \u001b[38;5;34m771\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_out         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ logits[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ patch_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ patch_reshape       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ patch_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln1_0               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ patch_reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha_0               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ ln1_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ ln1_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res1_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ patch_reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ mha_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln2_0               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res1_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp1_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ ln2_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ drop_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp1_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp2_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ drop_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res2_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res1_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ mlp2_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln1_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res2_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ ln1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ ln1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res2_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ mha_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln2_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ ln2_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ drop_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ drop_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ mlp2_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln1_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res2_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ ln1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ ln1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res2_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ mha_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ln2_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ ln2_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ drop_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlp2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ drop_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ mlp2_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res2_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ projectC (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ global_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rnn_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ projectC[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │ rnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ projectC[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_alpha_dense  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_alpha        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fusion_alpha_den… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ alpha_expand        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fusion_alpha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ alpha_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ projectC[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ head_ln             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ fusion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ head_fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ head_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_fc1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_out         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ logits[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,584,516\u001b[0m (6.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,584,516</span> (6.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,584,516\u001b[0m (6.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,584,516</span> (6.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model, optimizers\n",
        "\n",
        "def patch_embed_model(input_shape=(IMG_SIZE,IMG_SIZE,3), patch_size=16, embed_dim=64):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    # conv with stride=patch_size to get patch embeddings\n",
        "    x = layers.Conv2D(embed_dim, kernel_size=patch_size, strides=patch_size, padding='valid')(inp)\n",
        "    x = layers.Reshape((-1, embed_dim))(x)  # (patches, embed_dim)\n",
        "    return Model(inp, x, name=\"patcher\")\n",
        "\n",
        "def transformer_block(seq_in, embed_dim=64, num_heads=4, mlp_dim=128):\n",
        "    x1 = layers.LayerNormalization()(seq_in)\n",
        "    att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x1, x1)\n",
        "    x2 = layers.Add()([seq_in, att])\n",
        "    y = layers.LayerNormalization()(x2)\n",
        "    y = layers.Dense(mlp_dim, activation='gelu')(y)\n",
        "    y = layers.Dense(embed_dim)(y)\n",
        "    out = layers.Add()([x2, y])\n",
        "    return out\n",
        "\n",
        "def build_hybrid_single(embed_dim=64, rnn_units=128, num_classes=len(classes)):\n",
        "    img_in = layers.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "    patcher = patch_embed_model()\n",
        "    seq = patcher(img_in)  # (patches, embed_dim)\n",
        "    x = seq\n",
        "    # 2 transformer blocks\n",
        "    x = transformer_block(x, embed_dim)\n",
        "    x = transformer_block(x, embed_dim)\n",
        "    C_t = layers.GlobalAveragePooling1D()(x)   # context vector\n",
        "    # project context and pass through GRU (single timestep)\n",
        "    projC = layers.Dense(rnn_units)(C_t)\n",
        "    H_t = layers.Reshape((1, rnn_units))(projC)\n",
        "    H_t = layers.GRU(rnn_units, return_sequences=False)(H_t)\n",
        "    # learnable fusion alpha simulated with a small Dense + sigmoid\n",
        "    alpha = layers.Dense(1, activation='sigmoid')(layers.Concatenate()([H_t, projC]))\n",
        "    alpha = layers.Flatten()(alpha)  # scalar between 0-1\n",
        "    # fuse\n",
        "    F_t = layers.Lambda(lambda z: z[0]*z[1] + (1.0 - z[0])*z[2])([alpha, H_t, projC])\n",
        "    x = layers.LayerNormalization()(F_t)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(img_in, out, name=\"hybrid_single\")\n",
        "\n",
        "model = build_hybrid_single()\n",
        "model.compile(optimizer=optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1297
        },
        "id": "oH-ob3_5abUs",
        "outputId": "cba6e9cc-c33c-4497-adc9-1013ad06be1e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"hybrid_single\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hybrid_single\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ patcher             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,216\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ patcher[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ patcher[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m8,256\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m8,256\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m99,072\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m256\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ patcher             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,216</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ patcher[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ patcher[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m340,420\u001b[0m (1.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,420</span> (1.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m340,420\u001b[0m (1.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,420</span> (1.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "EPOCHS = 20\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_loss'),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "]\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gts5C4vPadHp",
        "outputId": "57b3b5e1-e4c3-435a-8584-a0b4d4a71ac4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.5697 - loss: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 479ms/step - accuracy: 0.5680 - loss: 0.9886 - val_accuracy: 0.6471 - val_loss: 0.9007\n",
            "Epoch 2/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 485ms/step - accuracy: 0.5801 - loss: 1.0003 - val_accuracy: 0.6471 - val_loss: 0.9146\n",
            "Epoch 3/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - accuracy: 0.5744 - loss: 0.9698"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 552ms/step - accuracy: 0.5762 - loss: 0.9687 - val_accuracy: 0.6471 - val_loss: 0.8824\n",
            "Epoch 4/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5646 - loss: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 410ms/step - accuracy: 0.5680 - loss: 0.9856 - val_accuracy: 0.6471 - val_loss: 0.8751\n",
            "Epoch 5/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 487ms/step - accuracy: 0.5890 - loss: 0.9585 - val_accuracy: 0.6471 - val_loss: 0.8815\n",
            "Epoch 6/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 499ms/step - accuracy: 0.6357 - loss: 0.9011 - val_accuracy: 0.6471 - val_loss: 0.8863\n",
            "Epoch 7/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 396ms/step - accuracy: 0.6474 - loss: 0.9210 - val_accuracy: 0.6471 - val_loss: 0.9037\n",
            "Epoch 8/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.5729 - loss: 0.9317"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 419ms/step - accuracy: 0.5769 - loss: 0.9315 - val_accuracy: 0.6471 - val_loss: 0.8704\n",
            "Epoch 9/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 527ms/step - accuracy: 0.6212 - loss: 0.9316 - val_accuracy: 0.6471 - val_loss: 0.8807\n",
            "Epoch 10/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 492ms/step - accuracy: 0.6091 - loss: 0.9488 - val_accuracy: 0.6471 - val_loss: 0.8826\n",
            "Epoch 11/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.6711 - loss: 0.8828 - val_accuracy: 0.6471 - val_loss: 0.8718\n",
            "Epoch 12/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 467ms/step - accuracy: 0.6248 - loss: 0.9274 - val_accuracy: 0.7059 - val_loss: 0.8722\n",
            "Epoch 13/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.6441 - loss: 0.8945"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 533ms/step - accuracy: 0.6430 - loss: 0.8977 - val_accuracy: 0.6765 - val_loss: 0.8573\n",
            "Epoch 14/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 547ms/step - accuracy: 0.6345 - loss: 0.9016"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 603ms/step - accuracy: 0.6346 - loss: 0.9015 - val_accuracy: 0.6765 - val_loss: 0.8502\n",
            "Epoch 15/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.6384 - loss: 0.8911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6374 - loss: 0.8919 - val_accuracy: 0.6765 - val_loss: 0.8437\n",
            "Epoch 16/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.6082 - loss: 0.9232"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 416ms/step - accuracy: 0.6109 - loss: 0.9199 - val_accuracy: 0.7059 - val_loss: 0.8358\n",
            "Epoch 17/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.6648 - loss: 0.8581"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 513ms/step - accuracy: 0.6602 - loss: 0.8628 - val_accuracy: 0.7059 - val_loss: 0.8348\n",
            "Epoch 18/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 503ms/step - accuracy: 0.6630 - loss: 0.8417 - val_accuracy: 0.6765 - val_loss: 0.8389\n",
            "Epoch 19/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.5884 - loss: 0.9027 - val_accuracy: 0.6912 - val_loss: 0.8425\n",
            "Epoch 20/20\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 0.6659 - loss: 0.8564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 500ms/step - accuracy: 0.6654 - loss: 0.8553 - val_accuracy: 0.6912 - val_loss: 0.8033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save native Keras format (.keras)\n",
        "model.save(\"hybrid_model.keras\", include_optimizer=False)\n",
        "print(\"Saved Keras native file:\", \"hybrid_model.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R1uajn3Wagqz",
        "outputId": "6721a64d-a88f-48f2-b465-c80c0ddd998f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Keras native file: hybrid_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io, os\n",
        "\n",
        "# load model (SavedModel directory preferred)\n",
        "MODEL_PATH = \"hybrid_saved_model_tf\"  # or \"hybrid_model.keras\" or \"hybrid_model_export.h5\"\n",
        "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "# match the class order used during training\n",
        "CLASSES = [\"benign\", \"malign\", \"normal\"]\n",
        "\n",
        "def preprocess_bytes(b):\n",
        "    img = Image.open(io.BytesIO(b)).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)  # 3 channels\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return \"<h3>POST image to /predict (form field 'file')</h3>\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"no file\"}), 400\n",
        "    f = request.files['file'].read()\n",
        "    x = preprocess_bytes(f)\n",
        "    preds = model.predict(x)\n",
        "    idx = int(np.argmax(preds[0]))\n",
        "    return jsonify({\"class\": CLASSES[idx], \"confidence\": float(np.max(preds[0]))})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f2kmgbNqbVdu",
        "outputId": "066acc9f-985d-4f07-bb3d-4ca5f27b9c10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"hybrid_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4A-h_Oktbq0Q",
        "outputId": "dfc03642-e076-4409-8985-0059f7cf2128"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_233b5d2d-7c63-4577-bda1-9fbc32c373a4\", \"hybrid_model.keras\", 7021171)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "MODEL_PATH = \"hybrid_saved_model\"   # ensure this folder exists in Colab working dir\n",
        "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "CLASS_NAMES = [\"benign\", \"malignant\", \"normal\"]  # match training order\n",
        "\n",
        "def preprocess_img_bytes(img_bytes):\n",
        "    img = Image.open(io.BytesIO(img_bytes)).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"<h3>Upload image via POST /predict (form-data, field name 'file')</h3>\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"no file provided\"}), 400\n",
        "    f = request.files['file'].read()\n",
        "    x = preprocess_img_bytes(f)\n",
        "    preds = model.predict(x)\n",
        "    idx = int(np.argmax(preds[0]))\n",
        "    return jsonify({\"class\": CLASS_NAMES[idx], \"confidence\": float(np.max(preds[0]))})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WZ6mvBMXcMcm",
        "outputId": "b306e047-906a-4597-a902-171664c33500"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell: Compute class weights, add sample_weight to train_ds, and retrain =====\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# 1) Class counts\n",
        "counts = Counter(train_labels)  # train_labels from earlier data-split\n",
        "print(\"Train class counts:\", counts)\n",
        "for i,c in enumerate(classes):\n",
        "    print(f\"  {i}: {c} -> {counts.get(i,0)} samples\")\n",
        "\n",
        "# 2) compute class weights (sklearn helper)\n",
        "unique_classes = np.unique(train_labels)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=np.array(train_labels))\n",
        "class_weight_dict = {int(cls): float(w) for cls, w in zip(unique_classes, class_weights)}\n",
        "print(\"Computed class_weight:\", class_weight_dict)\n",
        "\n",
        "# 3) Build a weighted train dataset that yields (image, onehot_label, sample_weight)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_image(path):\n",
        "    image_bytes = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(image_bytes, channels=1, expand_animations=False)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = tf.image.grayscale_to_rgb(img)\n",
        "    return img\n",
        "\n",
        "# create tf.constant lists for train\n",
        "train_files_tf = tf.constant(train_files)\n",
        "train_labels_tf = tf.constant(train_labels, dtype=tf.int32)\n",
        "\n",
        "def map_with_weight(path, label):\n",
        "    img = preprocess_image(path)\n",
        "    onehot = tf.one_hot(label, depth=len(classes))\n",
        "    # compute sample weight from label using class_weight_dict\n",
        "    # (convert dict to tensor lookup)\n",
        "    # build a small tensor containing weights in class index order\n",
        "    weights_tensor = tf.constant([class_weight_dict.get(i, 1.0) for i in range(len(classes))], dtype=tf.float32)\n",
        "    sample_w = tf.gather(weights_tensor, label)\n",
        "    return img, onehot, sample_w\n",
        "\n",
        "weighted_train_ds = tf.data.Dataset.from_tensor_slices((train_files_tf, train_labels_tf))\n",
        "weighted_train_ds = weighted_train_ds.shuffle(buffer_size=len(train_files), seed=42)\n",
        "weighted_train_ds = weighted_train_ds.map(map_with_weight, num_parallel_calls=AUTOTUNE)\n",
        "weighted_train_ds = weighted_train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# val and test remain same but ensure they produce (img, onehot) only\n",
        "val_files_tf = tf.constant(val_files)\n",
        "val_labels_tf = tf.constant(val_labels, dtype=tf.int32)\n",
        "def map_no_weight(path, label):\n",
        "    img = preprocess_image(path)\n",
        "    return img, tf.one_hot(label, depth=len(classes))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_files_tf, val_labels_tf)).map(map_no_weight, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# quick sanity\n",
        "for imgs, labs, sw in weighted_train_ds.take(1):\n",
        "    print(\"Weighted train batch shapes:\", imgs.shape, labs.shape, sw.shape)\n",
        "    print(\"Sample weights in batch (first 8):\", sw.numpy()[:8])\n",
        "\n",
        "# 4) Retrain: use sample_weight coming from dataset. Keras will accept datasets yielding (x, y, sample_weight)\n",
        "EPOCHS = 10\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_hybrid_weighted.h5\", save_best_only=True, monitor='val_loss', verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Starting weighted retraining...\")\n",
        "history = model.fit(weighted_train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n",
        "\n",
        "# 5) Evaluate again on test set (rebuild test dataset to (img, onehot))\n",
        "test_files_tf = tf.constant(test_files)\n",
        "test_labels_tf = tf.constant(test_labels, dtype=tf.int32)\n",
        "test_ds_eval = tf.data.Dataset.from_tensor_slices((test_files_tf, test_labels_tf)).map(map_no_weight, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"Evaluating on test set after weighted retraining:\")\n",
        "res = model.evaluate(test_ds_eval)\n",
        "print(\"Test loss/acc:\", res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MyXJiEUUcOJZ",
        "outputId": "a9c47c09-7901-4bd4-b6dd-82e5781d018b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class counts: Counter({2: 337, 0: 137, 1: 72})\n",
            "  0: benign -> 137 samples\n",
            "  1: malign -> 72 samples\n",
            "  2: normal -> 337 samples\n",
            "Computed class_weight: {0: 1.3284671532846715, 1: 2.5277777777777777, 2: 0.5400593471810089}\n",
            "Weighted train batch shapes: (32, 224, 224, 3) (32, 3) (32,)\n",
            "Sample weights in batch (first 8): [0.5400593 0.5400593 0.5400593 0.5400593 0.5400593 0.5400593 2.5277777\n",
            " 0.5400593]\n",
            "Starting weighted retraining...\n",
            "Epoch 1/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 0.6414 - loss: 0.9905\n",
            "Epoch 1: val_loss improved from inf to 1.09925, saving model to best_hybrid_weighted.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 502ms/step - accuracy: 0.6282 - loss: 0.9974 - val_accuracy: 0.2941 - val_loss: 1.0993\n",
            "Epoch 2/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.3595 - loss: 1.0729\n",
            "Epoch 2: val_loss improved from 1.09925 to 0.94774, saving model to best_hybrid_weighted.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 549ms/step - accuracy: 0.3655 - loss: 1.0711 - val_accuracy: 0.6471 - val_loss: 0.9477\n",
            "Epoch 3/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.5782 - loss: 1.0335\n",
            "Epoch 3: val_loss did not improve from 0.94774\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 399ms/step - accuracy: 0.5775 - loss: 1.0330 - val_accuracy: 0.5294 - val_loss: 0.9757\n",
            "Epoch 4/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.5355 - loss: 1.0279\n",
            "Epoch 4: val_loss improved from 0.94774 to 0.93042, saving model to best_hybrid_weighted.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 458ms/step - accuracy: 0.5362 - loss: 1.0257 - val_accuracy: 0.5147 - val_loss: 0.9304\n",
            "Epoch 5/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.5459 - loss: 1.0320\n",
            "Epoch 5: val_loss improved from 0.93042 to 0.84284, saving model to best_hybrid_weighted.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 532ms/step - accuracy: 0.5467 - loss: 1.0290 - val_accuracy: 0.6471 - val_loss: 0.8428\n",
            "Epoch 6/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 0.6770 - loss: 0.9364\n",
            "Epoch 6: val_loss did not improve from 0.84284\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - accuracy: 0.6703 - loss: 0.9447 - val_accuracy: 0.4706 - val_loss: 0.9900\n",
            "Epoch 7/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.4217 - loss: 1.0002\n",
            "Epoch 7: val_loss did not improve from 0.84284\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.4184 - loss: 1.0058 - val_accuracy: 0.4412 - val_loss: 1.0537\n",
            "Epoch 8/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.6243 - loss: 0.9752\n",
            "Epoch 8: val_loss did not improve from 0.84284\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 496ms/step - accuracy: 0.6226 - loss: 0.9772 - val_accuracy: 0.5441 - val_loss: 0.9960\n",
            "Epoch 9/10\n",
            "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.5302 - loss: 0.9812\n",
            "Epoch 9: val_loss did not improve from 0.84284\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.5220 - loss: 0.9832 - val_accuracy: 0.5735 - val_loss: 0.8997\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "Evaluating on test set after weighted retraining:\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step - accuracy: 0.5499 - loss: 1.0873\n",
            "Test loss/acc: [1.1065341234207153, 0.52173912525177]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and produce confusion matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the best checkpoint if it exists\n",
        "import os\n",
        "if os.path.exists(\"best_hybrid_weighted.h5\"):\n",
        "    print(\"Loading best_hybrid_weighted.h5\")\n",
        "    model = tf.keras.models.load_model(\"best_hybrid_weighted.h5\", compile=False)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "    print(\"No checkpoint found; using current model in memory.\")\n",
        "\n",
        "# Build test dataset for evaluation (no sample weights)\n",
        "test_files_tf = tf.constant(test_files)\n",
        "test_labels_tf = tf.constant(test_labels, dtype=tf.int32)\n",
        "\n",
        "def map_no_weight(path, label):\n",
        "    img = preprocess_image(path)\n",
        "    return img, tf.one_hot(label, depth=len(classes))\n",
        "\n",
        "test_ds_eval = tf.data.Dataset.from_tensor_slices((test_files_tf, test_labels_tf)).map(map_no_weight, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "res = model.evaluate(test_ds_eval)\n",
        "print(\"Test loss, accuracy:\", res)\n",
        "\n",
        "# Get preds & labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for imgs, labs in test_ds_eval:\n",
        "    preds = model.predict(imgs)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "    y_true.extend(np.argmax(labs.numpy(), axis=1))\n",
        "\n",
        "y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "plt.figure(figsize=(6,6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix (after weighted retrain)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=classes, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "tpFqiWF_cRJ1",
        "outputId": "4b61173a-5186-4696-a125-8681120b75d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best_hybrid_weighted.h5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 0.5499 - loss: 1.0873\n",
            "Test loss, accuracy: [1.1065341234207153, 0.52173912525177]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
            "Classes: ['benign', 'malign', 'normal']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.36      0.18      0.24        22\n",
            "      malign       0.33      0.33      0.33         9\n",
            "      normal       0.59      0.76      0.67        38\n",
            "\n",
            "    accuracy                           0.52        69\n",
            "   macro avg       0.43      0.43      0.41        69\n",
            "weighted avg       0.49      0.52      0.49        69\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, tensorflow as tf\n",
        "\n",
        "# model variable is in-memory `transfer_model` or `transfer_model` name used earlier.\n",
        "# If training finished and `transfer_model` exists, save it.\n",
        "if 'transfer_model' in globals():\n",
        "    print(\"Saving transfer_model to .keras and .h5\")\n",
        "    transfer_model.save(\"transfer_mobilenet_vecalpha.keras\", include_optimizer=False)\n",
        "    transfer_model.save(\"best_transfer_vecalpha.h5\", include_optimizer=False)\n",
        "else:\n",
        "    # if you used variable transfer_model name earlier, change to that name:\n",
        "    try:\n",
        "        transfer_model  # check existence\n",
        "    except NameError:\n",
        "        print(\"transfer_model not found in memory. Trying to use 'transfer_model' or 'transfer_model' checkpoint.\")\n",
        "    else:\n",
        "        transfer_model.save(\"transfer_mobilenet_vecalpha.keras\", include_optimizer=False)\n",
        "        transfer_model.save(\"best_transfer_vecalpha.h5\", include_optimizer=False)\n",
        "\n",
        "print(\"Files now in working dir:\", [f for f in os.listdir('.') if f.endswith(('.keras','.h5'))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V5FTSC5MeFmq",
        "outputId": "fa444cc7-acdc-4f5b-d275-19937e7569fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transfer_model not found in memory. Trying to use 'transfer_model' or 'transfer_model' checkpoint.\n",
            "Files now in working dir: ['best_model.h5', 'best_hybrid_weighted.h5', 'hybrid_model.keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil, os\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "drive_dir = \"/content/drive/MyDrive/hybrid_models\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "\n",
        "for fname in [\"transfer_mobilenet_vecalpha.keras\", \"best_transfer_vecalpha.h5\"]:\n",
        "    if os.path.exists(fname):\n",
        "        shutil.copy(fname, os.path.join(drive_dir, fname))\n",
        "        print(\"Copied\", fname, \"to\", drive_dir)\n",
        "    else:\n",
        "        print(\"File not found:\", fname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qDadataLebo7",
        "outputId": "29a90fda-64a6-4ba1-8d37-9ce2fc5bdb07"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File not found: transfer_mobilenet_vecalpha.keras\n",
            "File not found: best_transfer_vecalpha.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf, numpy as np\n",
        "from PIL import Image\n",
        "import io, os\n",
        "\n",
        "# Load the Keras file (works in Colab and local)\n",
        "MODEL_PATH = \"transfer_mobilenet_vecalpha.keras\"  # or \"best_transfer_vecalpha.h5\"\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    # try fallback\n",
        "    MODEL_PATH = \"best_transfer_vecalpha.h5\"\n",
        "\n",
        "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
        "model.summary()\n",
        "\n",
        "IMG_SIZE = 224\n",
        "CLASSES = [\"benign\",\"malign\",\"normal\"]  # must match training order\n",
        "\n",
        "def preprocess_bytes(b):\n",
        "    img = Image.open(io.BytesIO(b)).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)  # 3-channel\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return \"<h3>POST image to /predict (form field 'file')</h3>\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\":\"no file provided\"}), 400\n",
        "    f = request.files['file'].read()\n",
        "    x = preprocess_bytes(f)\n",
        "    preds = model.predict(x)\n",
        "    idx = int(preds.argmax(axis=1)[0])\n",
        "    return jsonify({\"class\": CLASSES[idx], \"confidence\": float(preds[0, idx])})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mkVA4CyZeqHh",
        "outputId": "3efeaad4-c68f-49d6-b3c9-6a9bf60ebf2f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# Flask app: rebuild model architecture, load weights, serve predictions\n",
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io, os\n",
        "\n",
        "# Path to your saved weights/file (change if different)\n",
        "WEIGHTS_H5 = \"best_transfer_vecalpha.h5\"\n",
        "# Alternatively you can use a .keras file but we'll prefer weights to avoid deserialization\n",
        "KERAS_FILE = \"transfer_mobilenet_vecalpha.keras\"\n",
        "\n",
        "# Reference to your uploaded paper (for logging or docs)\n",
        "PAPER_PATH = \"/mnt/data/952 Manuscript (1).pdf\"\n",
        "\n",
        "# Model rebuild function (must match the training architecture)\n",
        "def build_transfer_model(img_size=224, rnn_units=256, num_classes=3):\n",
        "    # augmentation kept minimal here (you can remove for inference)\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.05),\n",
        "        layers.RandomContrast(0.05),\n",
        "    ], name=\"data_augment_infer\")\n",
        "\n",
        "    inp = Input(shape=(img_size, img_size, 3), name=\"image_input\")\n",
        "    x = data_augmentation(inp)  # optional at inference; keeps consistency with training\n",
        "    # scale and preprocess for MobileNetV2 (training used preprocess_input on x * 255)\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x * 255.0)\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(img_size, img_size, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        pooling='avg'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "    features = base_model(x)  # (batch, feat_dim)\n",
        "\n",
        "    # project + GRU + vector alpha fusion (matches your trained architecture)\n",
        "    projC = layers.Dense(rnn_units, name=\"projectC\")(features)   # (batch, rnn_units)\n",
        "    H_in = layers.Reshape((1, rnn_units), name=\"rnn_input\")(projC)\n",
        "    H_t = layers.GRU(rnn_units, return_sequences=False, name=\"gru\")(H_in)  # (batch, rnn_units)\n",
        "\n",
        "    concat = layers.Concatenate(name=\"concat_HC\")([H_t, projC])\n",
        "    alpha_vec = layers.Dense(rnn_units, activation=\"sigmoid\", name=\"fusion_alpha_vec\")(concat)  # (batch, rnn_units)\n",
        "\n",
        "    # elementwise fusion: alpha * H_t + (1-alpha) * projC\n",
        "    alpha_mul_H = layers.Multiply(name=\"alpha_mul_H\")([alpha_vec, H_t])\n",
        "    one_minus_alpha = layers.Lambda(lambda z: 1.0 - z, name=\"one_minus_alpha\")(alpha_vec)\n",
        "    alpha_mul_C = layers.Multiply(name=\"alpha_mul_C\")([one_minus_alpha, projC])\n",
        "    F = layers.Add(name=\"fusion_add\")([alpha_mul_H, alpha_mul_C])  # (batch, rnn_units)\n",
        "\n",
        "    x = layers.LayerNormalization(name=\"head_ln\")(F)\n",
        "    x = layers.Dense(256, activation=\"relu\", name=\"head_fc\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    logits = layers.Dense(num_classes, name=\"logits\")(x)\n",
        "    outputs = layers.Activation(\"softmax\", dtype=\"float32\", name=\"softmax_out\")(logits)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=outputs, name=\"MobileNetV2_TransRNN_vecalpha_infer\")\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "NUM_CLASSES = 3  # adjust if different; your classes: ['benign','malign','normal']\n",
        "model = build_transfer_model(img_size=224, rnn_units=256, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Load weights: try .h5 weights first, then .keras fallback\n",
        "if os.path.exists(WEIGHTS_H5):\n",
        "    print(\"Loading weights from\", WEIGHTS_H5)\n",
        "    # if WEIGHTS_H5 contains full model config (H5) this will try to load the whole model and may fail,\n",
        "    # so prefer loading via model.load_weights() which expects weights-only HDF5.\n",
        "    try:\n",
        "        model.load_weights(WEIGHTS_H5)\n",
        "        print(\"Loaded weights into rebuilt architecture.\")\n",
        "    except Exception as e:\n",
        "        print(\"load_weights failed:\", e)\n",
        "        # Try loading a whole model file (rare) as fallback\n",
        "        try:\n",
        "            whole = tf.keras.models.load_model(WEIGHTS_H5, compile=False)\n",
        "            model.set_weights(whole.get_weights())\n",
        "            print(\"Loaded whole model and transferred weights.\")\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(\"Failed to load weights from H5. Details: %r ; %r\" % (e, e2))\n",
        "elif os.path.exists(KERAS_FILE):\n",
        "    print(\"Loading from Keras file:\", KERAS_FILE)\n",
        "    whole = tf.keras.models.load_model(KERAS_FILE, compile=False)  # may succeed for .keras\n",
        "    model.set_weights(whole.get_weights())\n",
        "    print(\"Loaded weights from .keras file.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"No model file found. Put weights H5 or .keras in working dir.\")\n",
        "\n",
        "# Freeze everything for inference (reduce memory)\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Class order must match the one used in training\n",
        "CLASSES = [\"benign\", \"malign\", \"normal\"]\n",
        "\n",
        "# simple preprocess for incoming bytes\n",
        "IMG_SIZE = 224\n",
        "def preprocess_bytes(b):\n",
        "    img = Image.open(io.BytesIO(b)).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "# Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    return f\"<h3>Model ready. Paper at: {PAPER_PATH}</h3><p>POST image to /predict (form field 'file')</p>\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\":\"no file provided\"}), 400\n",
        "    b = request.files['file'].read()\n",
        "    x = preprocess_bytes(b)\n",
        "    preds = model.predict(x)\n",
        "    idx = int(np.argmax(preds[0]))\n",
        "    return jsonify({\"class\": CLASSES[idx], \"confidence\": float(preds[0, idx])})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # when running locally use app.run(); in Colab we'll use flask-ngrok to forward\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "X_DVqiw3eswV",
        "outputId": "fa7ac024-031e-4409-d714-e503a6b5fe44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removed flask_ngrok setup as it conflicts with manual pyngrok management.\n",
        "# Starting the app in the background and managing ngrok separately is more robust.\n",
        "# This cell should now be empty or contain only comments after fixes."
      ],
      "metadata": {
        "id": "KNyrcIQ3e2w0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok flask\n"
      ],
      "metadata": {
        "id": "7DW7lkude-yu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import conf, ngrok\n",
        "token = input(\"Paste your ngrok authtoken (from https://dashboard.ngrok.com/get-started/your-authtoken) and press Enter: \").strip()\n",
        "if not token:\n",
        "    print(\"No token provided — you can still try creating a tunnel without a token, but it is recommended to set one.\")\n",
        "else:\n",
        "    conf.get_default().auth_token = token\n",
        "    print(\"ngrok auth token set.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P6z0YvWsfHHI",
        "outputId": "6d906fd1-4253-427a-8bfb-2f1046ebbd8b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your ngrok authtoken (from https://dashboard.ngrok.com/get-started/your-authtoken) and press Enter: 35jpcVLkNK0h8mmLNzjk9iw3ZEn_7crpBi2zn69wXhavuAkFE\n",
            "ngrok auth token set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate any existing ngrok tunnels to ensure a clean start\n",
        "ngrok.kill()\n",
        "\n",
        "# Open http tunnel to local port 5000 (where app.py runs)\n",
        "tunnel = ngrok.connect(5000, \"http\")\n",
        "print(\"ngrok tunnel public URL:\", tunnel.public_url)\n",
        "print(\"All tunnels:\", ngrok.get_tunnels())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u7KiGCrpfLnp",
        "outputId": "2e3419ea-0ff2-494b-f0cc-3e8c9f22ca69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok tunnel public URL: https://subaquatic-wittingly-sharon.ngrok-free.dev\n",
            "All tunnels: [<NgrokTunnel: \"https://subaquatic-wittingly-sharon.ngrok-free.dev\" -> \"http://localhost:5000\">]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python app.py > flask.log 2>&1 &\n",
        "!sleep 1 # Give app a moment to start\n",
        "!tail -n 20 flask.log"
      ],
      "metadata": {
        "id": "Fm2EwvYZgLqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "26fbb83b-e29d-4f2d-bf41-09675758222d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-22 14:00:52.544015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763820052.586595    3459 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763820052.596631    3459 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763820052.619869    3459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763820052.619915    3459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763820052.619918    3459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763820052.619921    3459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(5000, \"http\")\n",
        "print(\"Public URL:\", public_url)\n",
        "print(\"Active tunnels:\", ngrok.get_tunnels())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lEb8ajzCgf7z",
        "outputId": "2aedfd18-b3c2-47be-f9fc-606317aa01e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://subaquatic-wittingly-sharon.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
            "Active tunnels: [<NgrokTunnel: \"https://subaquatic-wittingly-sharon.ngrok-free.dev\" -> \"http://localhost:5000\">]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(5000, \"http\")\n",
        "print(\"Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WJzZDp7Lg5K2",
        "outputId": "6770c9d8-c984-4a10-90ef-0118ba514e9c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://subaquatic-wittingly-sharon.ngrok-free.dev\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/ultrasound_project/bus_uclm_separated/benign | sed -n '1,200p'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Lsoye_gQhV12",
        "outputId": "f6bfb0a1-d4eb-4e85-a2d1-8e1554f43cfe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 85756\n",
            "-rw-r--r-- 1 root root 498328 Nov 22 13:55 ALWI_000.png\n",
            "-rw-r--r-- 1 root root 469631 Nov 22 13:55 ALWI_002.png\n",
            "-rw-r--r-- 1 root root 512794 Nov 22 13:55 ALWI_003.png\n",
            "-rw-r--r-- 1 root root 513581 Nov 22 13:55 ALWI_004.png\n",
            "-rw-r--r-- 1 root root 501996 Nov 22 13:55 ALWI_005.png\n",
            "-rw-r--r-- 1 root root 470460 Nov 22 13:55 ALWI_007.png\n",
            "-rw-r--r-- 1 root root 498615 Nov 22 13:55 ALWI_008.png\n",
            "-rw-r--r-- 1 root root 498333 Nov 22 13:55 ALWI_009.png\n",
            "-rw-r--r-- 1 root root 494466 Nov 22 13:55 ALWI_010.png\n",
            "-rw-r--r-- 1 root root 494564 Nov 22 13:55 ALWI_011.png\n",
            "-rw-r--r-- 1 root root 444846 Nov 22 13:55 ALWI_015.png\n",
            "-rw-r--r-- 1 root root 460411 Nov 22 13:55 ALWI_016.png\n",
            "-rw-r--r-- 1 root root 439896 Nov 22 13:55 ALWI_017.png\n",
            "-rw-r--r-- 1 root root 478293 Nov 22 13:55 ALWI_018.png\n",
            "-rw-r--r-- 1 root root 621122 Nov 22 13:55 ALWI_019.png\n",
            "-rw-r--r-- 1 root root 484406 Nov 22 13:55 ALWI_020.png\n",
            "-rw-r--r-- 1 root root 465961 Nov 22 13:55 ALWI_021.png\n",
            "-rw-r--r-- 1 root root 457034 Nov 22 13:55 ALWI_022.png\n",
            "-rw-r--r-- 1 root root 622611 Nov 22 13:55 ALWI_023.png\n",
            "-rw-r--r-- 1 root root 482486 Nov 22 13:55 ALWI_026.png\n",
            "-rw-r--r-- 1 root root 520390 Nov 22 13:55 ALWI_027.png\n",
            "-rw-r--r-- 1 root root 480245 Nov 22 13:55 ANFO_002.png\n",
            "-rw-r--r-- 1 root root 566057 Nov 22 13:55 ANFO_003.png\n",
            "-rw-r--r-- 1 root root 455420 Nov 22 13:55 ANFO_004.png\n",
            "-rw-r--r-- 1 root root 549256 Nov 22 13:55 ANFO_005.png\n",
            "-rw-r--r-- 1 root root 484372 Nov 22 13:55 ANFO_006.png\n",
            "-rw-r--r-- 1 root root 465995 Nov 22 13:55 ANFO_007.png\n",
            "-rw-r--r-- 1 root root 504514 Nov 22 13:55 ANFO_009.png\n",
            "-rw-r--r-- 1 root root 446827 Nov 22 13:55 ASSC_000.png\n",
            "-rw-r--r-- 1 root root 489492 Nov 22 13:55 ASSC_001.png\n",
            "-rw-r--r-- 1 root root 453404 Nov 22 13:55 ASSC_002.png\n",
            "-rw-r--r-- 1 root root 421732 Nov 22 13:55 ASSC_003.png\n",
            "-rw-r--r-- 1 root root 436254 Nov 22 13:55 ASSC_005.png\n",
            "-rw-r--r-- 1 root root 443635 Nov 22 13:55 ASSC_006.png\n",
            "-rw-r--r-- 1 root root 426659 Nov 22 13:55 ASSC_014.png\n",
            "-rw-r--r-- 1 root root 441685 Nov 22 13:55 ASSC_015.png\n",
            "-rw-r--r-- 1 root root 454912 Nov 22 13:55 ASSC_016.png\n",
            "-rw-r--r-- 1 root root 449234 Nov 22 13:55 ASSC_027.png\n",
            "-rw-r--r-- 1 root root 415530 Nov 22 13:55 ASSC_028.png\n",
            "-rw-r--r-- 1 root root 408704 Nov 22 13:55 CAWI_003.png\n",
            "-rw-r--r-- 1 root root 410325 Nov 22 13:55 CAWI_004.png\n",
            "-rw-r--r-- 1 root root 415030 Nov 22 13:55 CAWI_005.png\n",
            "-rw-r--r-- 1 root root 428453 Nov 22 13:55 CAWI_009.png\n",
            "-rw-r--r-- 1 root root 423440 Nov 22 13:55 CAWI_010.png\n",
            "-rw-r--r-- 1 root root 430567 Nov 22 13:55 CAWI_011.png\n",
            "-rw-r--r-- 1 root root 427357 Nov 22 13:55 CAWI_012.png\n",
            "-rw-r--r-- 1 root root 436780 Nov 22 13:55 CAWI_013.png\n",
            "-rw-r--r-- 1 root root 445464 Nov 22 13:55 CAWI_016.png\n",
            "-rw-r--r-- 1 root root 516454 Nov 22 13:55 CAWI_023.png\n",
            "-rw-r--r-- 1 root root 422402 Nov 22 13:55 CHVI_020.png\n",
            "-rw-r--r-- 1 root root 425439 Nov 22 13:55 CHVI_021.png\n",
            "-rw-r--r-- 1 root root 444005 Nov 22 13:55 COST_010.png\n",
            "-rw-r--r-- 1 root root 429660 Nov 22 13:55 COST_011.png\n",
            "-rw-r--r-- 1 root root 619460 Nov 22 13:55 DAPA_001.png\n",
            "-rw-r--r-- 1 root root 613521 Nov 22 13:55 DAPA_002.png\n",
            "-rw-r--r-- 1 root root 530564 Nov 22 13:55 DAPA_005.png\n",
            "-rw-r--r-- 1 root root 471032 Nov 22 13:55 DAPA_006.png\n",
            "-rw-r--r-- 1 root root 443694 Nov 22 13:55 DAPA_007.png\n",
            "-rw-r--r-- 1 root root 498991 Nov 22 13:55 DAPA_012.png\n",
            "-rw-r--r-- 1 root root 471172 Nov 22 13:55 DAPA_013.png\n",
            "-rw-r--r-- 1 root root 471119 Nov 22 13:55 DAPA_014.png\n",
            "-rw-r--r-- 1 root root 481932 Nov 22 13:55 DAPA_015.png\n",
            "-rw-r--r-- 1 root root 455081 Nov 22 13:55 DAPA_016.png\n",
            "-rw-r--r-- 1 root root 517577 Nov 22 13:55 DAPA_017.png\n",
            "-rw-r--r-- 1 root root 520704 Nov 22 13:55 DAPA_019.png\n",
            "-rw-r--r-- 1 root root 617862 Nov 22 13:55 DAPA_020.png\n",
            "-rw-r--r-- 1 root root 627375 Nov 22 13:55 DAPA_021.png\n",
            "-rw-r--r-- 1 root root 533079 Nov 22 13:55 DAPA_022.png\n",
            "-rw-r--r-- 1 root root 537373 Nov 22 13:55 DAPA_023.png\n",
            "-rw-r--r-- 1 root root 539090 Nov 22 13:55 DAPA_024.png\n",
            "-rw-r--r-- 1 root root 487818 Nov 22 13:55 DAPA_025.png\n",
            "-rw-r--r-- 1 root root 618016 Nov 22 13:55 DAPA_029.png\n",
            "-rw-r--r-- 1 root root 537207 Nov 22 13:55 DAPA_031.png\n",
            "-rw-r--r-- 1 root root 613979 Nov 22 13:55 DAPA_032.png\n",
            "-rw-r--r-- 1 root root 523886 Nov 22 13:55 DAPA_033.png\n",
            "-rw-r--r-- 1 root root 617811 Nov 22 13:55 DAPA_034.png\n",
            "-rw-r--r-- 1 root root 614507 Nov 22 13:55 DAPA_035.png\n",
            "-rw-r--r-- 1 root root 524779 Nov 22 13:55 DAPA_038.png\n",
            "-rw-r--r-- 1 root root 429490 Nov 22 13:55 FLBA_017.png\n",
            "-rw-r--r-- 1 root root 541981 Nov 22 13:55 FUHI_007.png\n",
            "-rw-r--r-- 1 root root 465994 Nov 22 13:55 HESN_002.png\n",
            "-rw-r--r-- 1 root root 458760 Nov 22 13:55 HESN_003.png\n",
            "-rw-r--r-- 1 root root 464697 Nov 22 13:55 HESN_004.png\n",
            "-rw-r--r-- 1 root root 491809 Nov 22 13:55 HESN_005.png\n",
            "-rw-r--r-- 1 root root 539253 Nov 22 13:55 HUBL_015.png\n",
            "-rw-r--r-- 1 root root 498515 Nov 22 13:55 KIFO_003.png\n",
            "-rw-r--r-- 1 root root 557765 Nov 22 13:55 KIFO_004.png\n",
            "-rw-r--r-- 1 root root 529667 Nov 22 13:55 KIFO_005.png\n",
            "-rw-r--r-- 1 root root 532981 Nov 22 13:55 KIFO_006.png\n",
            "-rw-r--r-- 1 root root 514736 Nov 22 13:55 KIFO_007.png\n",
            "-rw-r--r-- 1 root root 619118 Nov 22 13:55 KIFO_008.png\n",
            "-rw-r--r-- 1 root root 613315 Nov 22 13:55 KIFO_009.png\n",
            "-rw-r--r-- 1 root root 491749 Nov 22 13:55 MENE_017.png\n",
            "-rw-r--r-- 1 root root 423551 Nov 22 13:55 NIRO_000.png\n",
            "-rw-r--r-- 1 root root 525792 Nov 22 13:55 ORPE_001.png\n",
            "-rw-r--r-- 1 root root 533503 Nov 22 13:55 ORPE_011.png\n",
            "-rw-r--r-- 1 root root 491767 Nov 22 13:55 ORPE_014.png\n",
            "-rw-r--r-- 1 root root 582808 Nov 22 13:55 ORPE_015.png\n",
            "-rw-r--r-- 1 root root 501992 Nov 22 13:55 ORPE_017.png\n",
            "-rw-r--r-- 1 root root 539196 Nov 22 13:55 ORPE_019.png\n",
            "-rw-r--r-- 1 root root 630356 Nov 22 13:55 ORPE_020.png\n",
            "-rw-r--r-- 1 root root 455093 Nov 22 13:55 ORPE_021.png\n",
            "-rw-r--r-- 1 root root 545672 Nov 22 13:55 ORPE_022.png\n",
            "-rw-r--r-- 1 root root 546163 Nov 22 13:55 ORPE_023.png\n",
            "-rw-r--r-- 1 root root 612283 Nov 22 13:55 OSCU_012.png\n",
            "-rw-r--r-- 1 root root 601977 Nov 22 13:55 OSCU_013.png\n",
            "-rw-r--r-- 1 root root 477571 Nov 22 13:55 OSCU_014.png\n",
            "-rw-r--r-- 1 root root 484151 Nov 22 13:55 OSCU_015.png\n",
            "-rw-r--r-- 1 root root 481065 Nov 22 13:55 OSCU_016.png\n",
            "-rw-r--r-- 1 root root 471099 Nov 22 13:55 OSCU_017.png\n",
            "-rw-r--r-- 1 root root 508254 Nov 22 13:55 OSCU_019.png\n",
            "-rw-r--r-- 1 root root 508293 Nov 22 13:55 OSCU_020.png\n",
            "-rw-r--r-- 1 root root 508688 Nov 22 13:55 OSCU_021.png\n",
            "-rw-r--r-- 1 root root 507570 Nov 22 13:55 OSCU_022.png\n",
            "-rw-r--r-- 1 root root 499983 Nov 22 13:55 OSCU_023.png\n",
            "-rw-r--r-- 1 root root 495469 Nov 22 13:55 PLBA_001.png\n",
            "-rw-r--r-- 1 root root 481793 Nov 22 13:55 PLBA_002.png\n",
            "-rw-r--r-- 1 root root 514208 Nov 22 13:55 PLBA_003.png\n",
            "-rw-r--r-- 1 root root 492016 Nov 22 13:55 PLBA_008.png\n",
            "-rw-r--r-- 1 root root 516817 Nov 22 13:55 PLBA_009.png\n",
            "-rw-r--r-- 1 root root 500635 Nov 22 13:55 PLBA_010.png\n",
            "-rw-r--r-- 1 root root 471300 Nov 22 13:55 PLBA_013.png\n",
            "-rw-r--r-- 1 root root 484130 Nov 22 13:55 PLBA_014.png\n",
            "-rw-r--r-- 1 root root 530721 Nov 22 13:55 PLBA_018.png\n",
            "-rw-r--r-- 1 root root 505778 Nov 22 13:55 PLBA_019.png\n",
            "-rw-r--r-- 1 root root 524138 Nov 22 13:55 PLBA_024.png\n",
            "-rw-r--r-- 1 root root 508926 Nov 22 13:55 POFR_011.png\n",
            "-rw-r--r-- 1 root root 617899 Nov 22 13:55 POFR_012.png\n",
            "-rw-r--r-- 1 root root 617313 Nov 22 13:55 POFR_013.png\n",
            "-rw-r--r-- 1 root root 518548 Nov 22 13:55 POFR_017.png\n",
            "-rw-r--r-- 1 root root 519165 Nov 22 13:55 POFR_022.png\n",
            "-rw-r--r-- 1 root root 433125 Nov 22 13:55 RARE_000.png\n",
            "-rw-r--r-- 1 root root 551094 Nov 22 13:55 RARE_001.png\n",
            "-rw-r--r-- 1 root root 555112 Nov 22 13:55 RARE_002.png\n",
            "-rw-r--r-- 1 root root 555721 Nov 22 13:55 RARE_003.png\n",
            "-rw-r--r-- 1 root root 552251 Nov 22 13:55 RARE_004.png\n",
            "-rw-r--r-- 1 root root 467496 Nov 22 13:55 SECH_008.png\n",
            "-rw-r--r-- 1 root root 472440 Nov 22 13:55 SECH_009.png\n",
            "-rw-r--r-- 1 root root 461770 Nov 22 13:55 SECH_010.png\n",
            "-rw-r--r-- 1 root root 460876 Nov 22 13:55 SECH_011.png\n",
            "-rw-r--r-- 1 root root 455866 Nov 22 13:55 SECH_012.png\n",
            "-rw-r--r-- 1 root root 622649 Nov 22 13:55 SHST_005.png\n",
            "-rw-r--r-- 1 root root 613887 Nov 22 13:55 SHST_006.png\n",
            "-rw-r--r-- 1 root root 515951 Nov 22 13:55 SHST_008.png\n",
            "-rw-r--r-- 1 root root 489690 Nov 22 13:55 SHST_009.png\n",
            "-rw-r--r-- 1 root root 517638 Nov 22 13:55 SHST_011.png\n",
            "-rw-r--r-- 1 root root 491871 Nov 22 13:55 STSP_001.png\n",
            "-rw-r--r-- 1 root root 600534 Nov 22 13:55 STSP_002.png\n",
            "-rw-r--r-- 1 root root 433885 Nov 22 13:55 STSP_003.png\n",
            "-rw-r--r-- 1 root root 438865 Nov 22 13:55 STSP_004.png\n",
            "-rw-r--r-- 1 root root 498280 Nov 22 13:55 STSP_018.png\n",
            "-rw-r--r-- 1 root root 500875 Nov 22 13:55 STSP_019.png\n",
            "-rw-r--r-- 1 root root 506765 Nov 22 13:55 STSP_020.png\n",
            "-rw-r--r-- 1 root root 521401 Nov 22 13:55 STSP_026.png\n",
            "-rw-r--r-- 1 root root 511066 Nov 22 13:55 TOCI_003.png\n",
            "-rw-r--r-- 1 root root 506155 Nov 22 13:55 TOCI_005.png\n",
            "-rw-r--r-- 1 root root 515759 Nov 22 13:55 TOCI_008.png\n",
            "-rw-r--r-- 1 root root 521800 Nov 22 13:55 TOCI_012.png\n",
            "-rw-r--r-- 1 root root 529026 Nov 22 13:55 TOCI_013.png\n",
            "-rw-r--r-- 1 root root 502961 Nov 22 13:55 TOCI_020.png\n",
            "-rw-r--r-- 1 root root 510631 Nov 22 13:55 TOCI_021.png\n",
            "-rw-r--r-- 1 root root 490364 Nov 22 13:55 TOCI_022.png\n",
            "-rw-r--r-- 1 root root 514403 Nov 22 13:55 TOCI_023.png\n",
            "-rw-r--r-- 1 root root 507249 Nov 22 13:55 TOCI_024.png\n",
            "-rw-r--r-- 1 root root 484291 Nov 22 13:55 TOCI_031.png\n",
            "-rw-r--r-- 1 root root 497159 Nov 22 13:55 VITR_001.png\n",
            "-rw-r--r-- 1 root root 498817 Nov 22 13:55 VITR_003.png\n",
            "-rw-r--r-- 1 root root 499438 Nov 22 13:55 VITR_004.png\n",
            "-rw-r--r-- 1 root root 483487 Nov 22 13:55 VITR_005.png\n",
            "-rw-r--r-- 1 root root 479353 Nov 22 13:55 VITR_009.png\n",
            "-rw-r--r-- 1 root root 477325 Nov 22 13:55 VITR_010.png\n",
            "-rw-r--r-- 1 root root 432340 Nov 22 13:55 VITR_011.png\n",
            "-rw-r--r-- 1 root root 436275 Nov 22 13:55 VITR_012.png\n",
            "-rw-r--r-- 1 root root 463968 Nov 22 13:55 VITR_028.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultrasound_project/bus_uclm_separated/benign\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qGX26DoVhKSK",
        "outputId": "91ca5675-fb81-41c6-cd90-5bb0786ea15f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALWI_000.png  ASSC_015.png  DAPA_025.png  OSCU_013.png\tSECH_012.png\n",
            "ALWI_002.png  ASSC_016.png  DAPA_029.png  OSCU_014.png\tSHST_005.png\n",
            "ALWI_003.png  ASSC_027.png  DAPA_031.png  OSCU_015.png\tSHST_006.png\n",
            "ALWI_004.png  ASSC_028.png  DAPA_032.png  OSCU_016.png\tSHST_008.png\n",
            "ALWI_005.png  CAWI_003.png  DAPA_033.png  OSCU_017.png\tSHST_009.png\n",
            "ALWI_007.png  CAWI_004.png  DAPA_034.png  OSCU_019.png\tSHST_011.png\n",
            "ALWI_008.png  CAWI_005.png  DAPA_035.png  OSCU_020.png\tSTSP_001.png\n",
            "ALWI_009.png  CAWI_009.png  DAPA_038.png  OSCU_021.png\tSTSP_002.png\n",
            "ALWI_010.png  CAWI_010.png  FLBA_017.png  OSCU_022.png\tSTSP_003.png\n",
            "ALWI_011.png  CAWI_011.png  FUHI_007.png  OSCU_023.png\tSTSP_004.png\n",
            "ALWI_015.png  CAWI_012.png  HESN_002.png  PLBA_001.png\tSTSP_018.png\n",
            "ALWI_016.png  CAWI_013.png  HESN_003.png  PLBA_002.png\tSTSP_019.png\n",
            "ALWI_017.png  CAWI_016.png  HESN_004.png  PLBA_003.png\tSTSP_020.png\n",
            "ALWI_018.png  CAWI_023.png  HESN_005.png  PLBA_008.png\tSTSP_026.png\n",
            "ALWI_019.png  CHVI_020.png  HUBL_015.png  PLBA_009.png\tTOCI_003.png\n",
            "ALWI_020.png  CHVI_021.png  KIFO_003.png  PLBA_010.png\tTOCI_005.png\n",
            "ALWI_021.png  COST_010.png  KIFO_004.png  PLBA_013.png\tTOCI_008.png\n",
            "ALWI_022.png  COST_011.png  KIFO_005.png  PLBA_014.png\tTOCI_012.png\n",
            "ALWI_023.png  DAPA_001.png  KIFO_006.png  PLBA_018.png\tTOCI_013.png\n",
            "ALWI_026.png  DAPA_002.png  KIFO_007.png  PLBA_019.png\tTOCI_020.png\n",
            "ALWI_027.png  DAPA_005.png  KIFO_008.png  PLBA_024.png\tTOCI_021.png\n",
            "ANFO_002.png  DAPA_006.png  KIFO_009.png  POFR_011.png\tTOCI_022.png\n",
            "ANFO_003.png  DAPA_007.png  MENE_017.png  POFR_012.png\tTOCI_023.png\n",
            "ANFO_004.png  DAPA_012.png  NIRO_000.png  POFR_013.png\tTOCI_024.png\n",
            "ANFO_005.png  DAPA_013.png  ORPE_001.png  POFR_017.png\tTOCI_031.png\n",
            "ANFO_006.png  DAPA_014.png  ORPE_011.png  POFR_022.png\tVITR_001.png\n",
            "ANFO_007.png  DAPA_015.png  ORPE_014.png  RARE_000.png\tVITR_003.png\n",
            "ANFO_009.png  DAPA_016.png  ORPE_015.png  RARE_001.png\tVITR_004.png\n",
            "ASSC_000.png  DAPA_017.png  ORPE_017.png  RARE_002.png\tVITR_005.png\n",
            "ASSC_001.png  DAPA_019.png  ORPE_019.png  RARE_003.png\tVITR_009.png\n",
            "ASSC_002.png  DAPA_020.png  ORPE_020.png  RARE_004.png\tVITR_010.png\n",
            "ASSC_003.png  DAPA_021.png  ORPE_021.png  SECH_008.png\tVITR_011.png\n",
            "ASSC_005.png  DAPA_022.png  ORPE_022.png  SECH_009.png\tVITR_012.png\n",
            "ASSC_006.png  DAPA_023.png  ORPE_023.png  SECH_010.png\tVITR_028.png\n",
            "ASSC_014.png  DAPA_024.png  OSCU_012.png  SECH_011.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST -F \"file=@/content/ultrasound_project/bus_uclm_separated/benign/VITR_009.png\" https://subaquatic-wittingly-sharon.ngrok-free.dev/predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6FbKHLjIhRXV",
        "outputId": "e8cfda77-671b-451a-c75d-44246d560ef1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-22T14:00:54+0000 lvl=warn msg=\"failed to open private leg\" id=1750b98735fb privaddr=localhost:5000 err=\"dial tcp [::1]:5000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <meta name=\"author\" content=\"ngrok\">\n",
            "    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n",
            "    <link href=\"https://ngrok.com/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
            "    <meta name=\"robots\" content=\"noindex, nofollow\">\n",
            "    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n",
            "    <noscript>Traffic successfully made it to the ngrok agent, but the agent failed to establish a connection to the upstream web service at localhost:5000. (ERR_NGROK_8012)</noscript>\n",
            "    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n",
            "  </head>\n",
            "  <body class=\"h-full\" id=\"ngrok\">\n",
            "    <div id=\"root\" data-payload=\"eyJhZGRyIjoibG9jYWxob3N0OjUwMDAiLCJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiI4MDEyIiwiZXJyb3JUZXh0IjoiZGlhbCB0Y3AgWzo6MV06NTAwMDogY29ubmVjdDogY29ubmVjdGlvbiByZWZ1c2VkIiwibWVzc2FnZSI6IlRyYWZmaWMgc3VjY2Vzc2Z1bGx5IG1hZGUgaXQgdG8gdGhlIG5ncm9rIGFnZW50LCBidXQgdGhlIGFnZW50IGZhaWxlZCB0byBlc3RhYmxpc2ggYSBjb25uZWN0aW9uIHRvIHRoZSB1cHN0cmVhbSB3ZWIgc2VydmljZSBhdCBsb2NhbGhvc3Q6NTAwMC4iLCJzY2hlbWUiOiJodHRwIiwidGl0bGUiOiJCYWQgR2F0ZXdheSJ9\"></div>\n",
            "  </body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/ultrasound_project/bus_uclm_separated/benign/VITR_009.png\"\n",
        "print(\"Exists?\", os.path.exists(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QToQuLk5hd2H",
        "outputId": "455c0f4b-dd6a-425e-d235-ebf86f957c31"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultrasound_project/bus_uclm_separated/benign\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dl3F121rhgi6",
        "outputId": "995b984c-f846-4478-e634-0986c16fa155"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALWI_000.png  ASSC_015.png  DAPA_025.png  OSCU_013.png\tSECH_012.png\n",
            "ALWI_002.png  ASSC_016.png  DAPA_029.png  OSCU_014.png\tSHST_005.png\n",
            "ALWI_003.png  ASSC_027.png  DAPA_031.png  OSCU_015.png\tSHST_006.png\n",
            "ALWI_004.png  ASSC_028.png  DAPA_032.png  OSCU_016.png\tSHST_008.png\n",
            "ALWI_005.png  CAWI_003.png  DAPA_033.png  OSCU_017.png\tSHST_009.png\n",
            "ALWI_007.png  CAWI_004.png  DAPA_034.png  OSCU_019.png\tSHST_011.png\n",
            "ALWI_008.png  CAWI_005.png  DAPA_035.png  OSCU_020.png\tSTSP_001.png\n",
            "ALWI_009.png  CAWI_009.png  DAPA_038.png  OSCU_021.png\tSTSP_002.png\n",
            "ALWI_010.png  CAWI_010.png  FLBA_017.png  OSCU_022.png\tSTSP_003.png\n",
            "ALWI_011.png  CAWI_011.png  FUHI_007.png  OSCU_023.png\tSTSP_004.png\n",
            "ALWI_015.png  CAWI_012.png  HESN_002.png  PLBA_001.png\tSTSP_018.png\n",
            "ALWI_016.png  CAWI_013.png  HESN_003.png  PLBA_002.png\tSTSP_019.png\n",
            "ALWI_017.png  CAWI_016.png  HESN_004.png  PLBA_003.png\tSTSP_020.png\n",
            "ALWI_018.png  CAWI_023.png  HESN_005.png  PLBA_008.png\tSTSP_026.png\n",
            "ALWI_019.png  CHVI_020.png  HUBL_015.png  PLBA_009.png\tTOCI_003.png\n",
            "ALWI_020.png  CHVI_021.png  KIFO_003.png  PLBA_010.png\tTOCI_005.png\n",
            "ALWI_021.png  COST_010.png  KIFO_004.png  PLBA_013.png\tTOCI_008.png\n",
            "ALWI_022.png  COST_011.png  KIFO_005.png  PLBA_014.png\tTOCI_012.png\n",
            "ALWI_023.png  DAPA_001.png  KIFO_006.png  PLBA_018.png\tTOCI_013.png\n",
            "ALWI_026.png  DAPA_002.png  KIFO_007.png  PLBA_019.png\tTOCI_020.png\n",
            "ALWI_027.png  DAPA_005.png  KIFO_008.png  PLBA_024.png\tTOCI_021.png\n",
            "ANFO_002.png  DAPA_006.png  KIFO_009.png  POFR_011.png\tTOCI_022.png\n",
            "ANFO_003.png  DAPA_007.png  MENE_017.png  POFR_012.png\tTOCI_023.png\n",
            "ANFO_004.png  DAPA_012.png  NIRO_000.png  POFR_013.png\tTOCI_024.png\n",
            "ANFO_005.png  DAPA_013.png  ORPE_001.png  POFR_017.png\tTOCI_031.png\n",
            "ANFO_006.png  DAPA_014.png  ORPE_011.png  POFR_022.png\tVITR_001.png\n",
            "ANFO_007.png  DAPA_015.png  ORPE_014.png  RARE_000.png\tVITR_003.png\n",
            "ANFO_009.png  DAPA_016.png  ORPE_015.png  RARE_001.png\tVITR_004.png\n",
            "ASSC_000.png  DAPA_017.png  ORPE_017.png  RARE_002.png\tVITR_005.png\n",
            "ASSC_001.png  DAPA_019.png  ORPE_019.png  RARE_003.png\tVITR_009.png\n",
            "ASSC_002.png  DAPA_020.png  ORPE_020.png  RARE_004.png\tVITR_010.png\n",
            "ASSC_003.png  DAPA_021.png  ORPE_021.png  SECH_008.png\tVITR_011.png\n",
            "ASSC_005.png  DAPA_022.png  ORPE_022.png  SECH_009.png\tVITR_012.png\n",
            "ASSC_006.png  DAPA_023.png  ORPE_023.png  SECH_010.png\tVITR_028.png\n",
            "ASSC_014.png  DAPA_024.png  OSCU_012.png  SECH_011.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultrasound_project/bus_uclm_separated/malign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8Eh6AilFhh4o",
        "outputId": "ace2cfed-b75c-49b0-bee2-c89a67196139"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHCO_000.png  CODE_001.png  ELCO_006.png  HUBL_006.png\tPAGY_001.png\n",
            "CHSP_006.png  CODE_005.png  ELCO_007.png  HUBL_007.png\tPAGY_003.png\n",
            "CHSP_007.png  CODE_006.png  ELCO_008.png  HUBL_008.png\tPAGY_004.png\n",
            "CHSP_008.png  COPE_012.png  FLBA_004.png  HUBL_019.png\tPAGY_011.png\n",
            "CHSP_010.png  COPE_013.png  FLBA_005.png  HUBL_020.png\tSIBA_000.png\n",
            "CHVI_000.png  COPE_014.png  FLBA_019.png  LOTI_001.png\tSIBA_001.png\n",
            "CHVI_001.png  COPE_015.png  FLKA_002.png  LOTI_002.png\tSIBA_002.png\n",
            "CHVI_002.png  COPE_016.png  FLKA_003.png  LOTI_003.png\tSIBA_003.png\n",
            "CHVI_004.png  COPE_017.png  FLKA_004.png  LOTI_006.png\tSIBA_004.png\n",
            "CHVI_005.png  COPE_018.png  FLKA_005.png  LOTI_007.png\tSIBA_005.png\n",
            "CHVI_006.png  COVA_005.png  FUHI_000.png  LOTI_008.png\tSIBA_006.png\n",
            "CHVI_007.png  COVA_011.png  FUHI_003.png  MENE_000.png\tSIBA_007.png\n",
            "CHVI_014.png  COVA_012.png  FUHI_004.png  MENE_001.png\tSIBA_008.png\n",
            "CHVI_015.png  CRCI_000.png  FUHI_006.png  MENE_002.png\tUNCU_002.png\n",
            "CHVI_017.png  CRCI_001.png  FUHI_009.png  MENE_003.png\tUNCU_003.png\n",
            "CHVI_018.png  CRCI_002.png  HUBL_003.png  MENE_004.png\tUNCU_004.png\n",
            "CHVI_019.png  ELCO_004.png  HUBL_004.png  MENE_005.png\tUNCU_005.png\n",
            "CODE_000.png  ELCO_005.png  HUBL_005.png  MENE_018.png\tUNCU_006.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultrasound_project/bus_uclm_separated/normal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "juhVdfSAhl-g",
        "outputId": "09778c81-baf9-4f7c-feab-2e2c47a671fa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALWI_001.png  CHVI_003.png  FLKA_008.png  ORPE_010.png\tSHST_010.png\n",
            "ALWI_006.png  CHVI_008.png  FLKA_009.png  ORPE_012.png\tSTSP_000.png\n",
            "ALWI_012.png  CHVI_009.png  FLKA_010.png  ORPE_013.png\tSTSP_005.png\n",
            "ALWI_013.png  CHVI_010.png  FLKA_011.png  ORPE_016.png\tSTSP_006.png\n",
            "ALWI_014.png  CHVI_011.png  FLKA_012.png  ORPE_018.png\tSTSP_007.png\n",
            "ALWI_024.png  CHVI_012.png  FLKA_013.png  ORPE_024.png\tSTSP_008.png\n",
            "ALWI_025.png  CHVI_013.png  FLKA_014.png  ORPE_025.png\tSTSP_009.png\n",
            "ALWI_028.png  CHVI_016.png  FUHI_001.png  ORPE_026.png\tSTSP_010.png\n",
            "ANAT_000.png  CODE_002.png  FUHI_002.png  ORPE_027.png\tSTSP_011.png\n",
            "ANAT_001.png  CODE_003.png  FUHI_005.png  ORPE_028.png\tSTSP_012.png\n",
            "ANAT_002.png  CODE_004.png  FUHI_008.png  ORPE_029.png\tSTSP_013.png\n",
            "ANAT_003.png  COPE_000.png  HESN_000.png  OSCU_000.png\tSTSP_014.png\n",
            "ANAT_004.png  COPE_001.png  HESN_001.png  OSCU_001.png\tSTSP_015.png\n",
            "ANAT_005.png  COPE_002.png  HESN_006.png  OSCU_002.png\tSTSP_016.png\n",
            "ANAT_006.png  COPE_003.png  HESN_007.png  OSCU_003.png\tSTSP_017.png\n",
            "ANAT_007.png  COPE_004.png  HESN_008.png  OSCU_004.png\tSTSP_021.png\n",
            "ANAT_008.png  COPE_005.png  HESN_009.png  OSCU_005.png\tSTSP_022.png\n",
            "ANAT_009.png  COPE_006.png  HESN_010.png  OSCU_006.png\tSTSP_023.png\n",
            "ANAT_010.png  COPE_007.png  HESN_011.png  OSCU_007.png\tSTSP_024.png\n",
            "ANAT_011.png  COPE_008.png  HESN_012.png  OSCU_008.png\tSTSP_025.png\n",
            "ANAT_012.png  COPE_009.png  HUBL_000.png  OSCU_009.png\tSTSP_027.png\n",
            "ANAT_013.png  COPE_010.png  HUBL_001.png  OSCU_010.png\tTOCI_000.png\n",
            "ANAT_014.png  COPE_011.png  HUBL_002.png  OSCU_011.png\tTOCI_001.png\n",
            "ANAT_015.png  COST_000.png  HUBL_009.png  OSCU_018.png\tTOCI_002.png\n",
            "ANAT_016.png  COST_001.png  HUBL_010.png  OSCU_024.png\tTOCI_004.png\n",
            "ANAT_017.png  COST_002.png  HUBL_011.png  PAGY_000.png\tTOCI_006.png\n",
            "ANAT_018.png  COST_003.png  HUBL_012.png  PAGY_002.png\tTOCI_007.png\n",
            "ANAT_019.png  COST_004.png  HUBL_013.png  PAGY_005.png\tTOCI_009.png\n",
            "ANAT_020.png  COST_005.png  HUBL_014.png  PAGY_006.png\tTOCI_010.png\n",
            "ANFO_000.png  COST_006.png  HUBL_016.png  PAGY_007.png\tTOCI_011.png\n",
            "ANFO_001.png  COST_007.png  HUBL_017.png  PAGY_008.png\tTOCI_014.png\n",
            "ANFO_008.png  COST_008.png  HUBL_018.png  PAGY_009.png\tTOCI_015.png\n",
            "ANFO_010.png  COST_009.png  HUBL_021.png  PAGY_010.png\tTOCI_016.png\n",
            "ANFO_011.png  COVA_000.png  KIFO_000.png  PLBA_000.png\tTOCI_017.png\n",
            "ANFO_012.png  COVA_001.png  KIFO_001.png  PLBA_004.png\tTOCI_018.png\n",
            "ANFO_013.png  COVA_002.png  KIFO_002.png  PLBA_005.png\tTOCI_019.png\n",
            "ANFO_014.png  COVA_003.png  KIFO_010.png  PLBA_006.png\tTOCI_025.png\n",
            "ANFO_015.png  COVA_004.png  KIFO_011.png  PLBA_007.png\tTOCI_026.png\n",
            "ANFO_016.png  COVA_006.png  LOTI_000.png  PLBA_011.png\tTOCI_027.png\n",
            "ASSC_004.png  COVA_007.png  LOTI_004.png  PLBA_012.png\tTOCI_028.png\n",
            "ASSC_007.png  COVA_008.png  LOTI_005.png  PLBA_015.png\tTOCI_029.png\n",
            "ASSC_008.png  COVA_009.png  LOTI_009.png  PLBA_016.png\tTOCI_030.png\n",
            "ASSC_009.png  COVA_010.png  MENE_006.png  PLBA_017.png\tTOCI_032.png\n",
            "ASSC_010.png  COVA_013.png  MENE_007.png  PLBA_020.png\tTOCI_033.png\n",
            "ASSC_011.png  COVA_014.png  MENE_008.png  PLBA_021.png\tTOCI_034.png\n",
            "ASSC_012.png  COVA_015.png  MENE_009.png  PLBA_022.png\tTOCI_035.png\n",
            "ASSC_013.png  DAPA_000.png  MENE_010.png  PLBA_023.png\tTOCI_036.png\n",
            "ASSC_017.png  DAPA_003.png  MENE_011.png  POFR_000.png\tUNCU_000.png\n",
            "ASSC_018.png  DAPA_004.png  MENE_012.png  POFR_001.png\tUNCU_001.png\n",
            "ASSC_019.png  DAPA_008.png  MENE_013.png  POFR_002.png\tUNCU_007.png\n",
            "ASSC_020.png  DAPA_009.png  MENE_014.png  POFR_003.png\tUNCU_008.png\n",
            "ASSC_021.png  DAPA_010.png  MENE_015.png  POFR_004.png\tUNCU_009.png\n",
            "ASSC_022.png  DAPA_011.png  MENE_016.png  POFR_005.png\tUNCU_010.png\n",
            "ASSC_023.png  DAPA_018.png  NIRO_001.png  POFR_006.png\tUNCU_011.png\n",
            "ASSC_024.png  DAPA_026.png  NIRO_002.png  POFR_007.png\tUNCU_012.png\n",
            "ASSC_025.png  DAPA_027.png  NIRO_003.png  POFR_008.png\tVITR_000.png\n",
            "ASSC_026.png  DAPA_028.png  NIRO_004.png  POFR_009.png\tVITR_002.png\n",
            "CAWI_000.png  DAPA_030.png  NIRO_005.png  POFR_010.png\tVITR_006.png\n",
            "CAWI_001.png  DAPA_036.png  NIRO_006.png  POFR_014.png\tVITR_007.png\n",
            "CAWI_002.png  DAPA_037.png  NIRO_007.png  POFR_015.png\tVITR_008.png\n",
            "CAWI_006.png  ELCO_000.png  NIRO_008.png  POFR_016.png\tVITR_013.png\n",
            "CAWI_007.png  ELCO_001.png  NIRO_009.png  POFR_018.png\tVITR_014.png\n",
            "CAWI_008.png  ELCO_002.png  NIRO_010.png  POFR_019.png\tVITR_015.png\n",
            "CAWI_014.png  ELCO_003.png  NIRO_011.png  POFR_020.png\tVITR_016.png\n",
            "CAWI_015.png  FLBA_000.png  NIRO_012.png  POFR_021.png\tVITR_017.png\n",
            "CAWI_017.png  FLBA_001.png  NIRO_013.png  POFR_023.png\tVITR_018.png\n",
            "CAWI_018.png  FLBA_002.png  NIRO_014.png  POFR_024.png\tVITR_019.png\n",
            "CAWI_019.png  FLBA_003.png  NIRO_015.png  POFR_025.png\tVITR_020.png\n",
            "CAWI_020.png  FLBA_006.png  NIRO_016.png  POFR_026.png\tVITR_021.png\n",
            "CAWI_021.png  FLBA_007.png  NIRO_017.png  SECH_000.png\tVITR_022.png\n",
            "CAWI_022.png  FLBA_008.png  NIRO_018.png  SECH_001.png\tVITR_023.png\n",
            "CHCO_001.png  FLBA_009.png  NIRO_019.png  SECH_002.png\tVITR_024.png\n",
            "CHCO_002.png  FLBA_010.png  NIRO_020.png  SECH_003.png\tVITR_025.png\n",
            "CHCO_003.png  FLBA_011.png  NIRO_021.png  SECH_004.png\tVITR_026.png\n",
            "CHSP_000.png  FLBA_012.png  NIRO_022.png  SECH_005.png\tVITR_027.png\n",
            "CHSP_001.png  FLBA_013.png  ORPE_000.png  SECH_006.png\tWAQU_000.png\n",
            "CHSP_002.png  FLBA_014.png  ORPE_002.png  SECH_007.png\tWAQU_001.png\n",
            "CHSP_003.png  FLBA_015.png  ORPE_003.png  SECH_013.png\tWAQU_002.png\n",
            "CHSP_004.png  FLBA_016.png  ORPE_004.png  SHST_000.png\tWAQU_003.png\n",
            "CHSP_005.png  FLBA_018.png  ORPE_005.png  SHST_001.png\tWAQU_004.png\n",
            "CHSP_009.png  FLKA_000.png  ORPE_006.png  SHST_002.png\tWAQU_005.png\n",
            "CHSP_011.png  FLKA_001.png  ORPE_007.png  SHST_003.png\tWAQU_006.png\n",
            "CHSP_012.png  FLKA_006.png  ORPE_008.png  SHST_004.png\tWAQU_007.png\n",
            "CHSP_013.png  FLKA_007.png  ORPE_009.png  SHST_007.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST -F \"file=@/content/ultrasound_project/bus_uclm_separated/benign/VITR_009.png\" https://subaquatic-wittingly-sharon.ngrok-free.dev/predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n53IEp8phpMt",
        "outputId": "af3f931a-ca45-4b2c-e107-7308f581fa5d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-22T14:00:55+0000 lvl=warn msg=\"failed to open private leg\" id=ad511b2d6cea privaddr=localhost:5000 err=\"dial tcp [::1]:5000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <meta name=\"author\" content=\"ngrok\">\n",
            "    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n",
            "    <link href=\"https://ngrok.com/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
            "    <meta name=\"robots\" content=\"noindex, nofollow\">\n",
            "    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n",
            "    <noscript>Traffic successfully made it to the ngrok agent, but the agent failed to establish a connection to the upstream web service at localhost:5000. (ERR_NGROK_8012)</noscript>\n",
            "    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n",
            "  </head>\n",
            "  <body class=\"h-full\" id=\"ngrok\">\n",
            "    <div id=\"root\" data-payload=\"eyJhZGRyIjoibG9jYWxob3N0OjUwMDAiLCJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiI4MDEyIiwiZXJyb3JUZXh0IjoiZGlhbCB0Y3AgWzo6MV06NTAwMDogY29ubmVjdDogY29ubmVjdGlvbiByZWZ1c2VkIiwibWVzc2FnZSI6IlRyYWZmaWMgc3VjY2Vzc2Z1bGx5IG1hZGUgaXQgdG8gdGhlIG5ncm9rIGFnZW50LCBidXQgdGhlIGFnZW50IGZhaWxlZCB0byBlc3RhYmxpc2ggYSBjb25uZWN0aW9uIHRvIHRoZSB1cHN0cmVhbSB3ZWIgc2VydmljZSBhdCBsb2NhbGhvc3Q6NTAwMC4iLCJzY2hlbWUiOiJodHRwIiwidGl0bGUiOiJCYWQgR2F0ZXdheSJ9\"></div>\n",
            "  </body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check local endpoint\n",
        "!curl -v http://127.0.0.1:5000/ || echo \"local connection failed\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ekaKTQyhhtXz",
        "outputId": "0e7fc991-8d76-4335-eea9-ba18bd4755db"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   Trying 127.0.0.1:5000...\n",
            "* connect to 127.0.0.1 port 5000 failed: Connection refused\n",
            "* Failed to connect to 127.0.0.1 port 5000 after 0 ms: Connection refused\n",
            "* Closing connection 0\n",
            "curl: (7) Failed to connect to 127.0.0.1 port 5000 after 0 ms: Connection refused\n",
            "local connection failed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python app.py > flask.log 2>&1 &"
      ],
      "metadata": {
        "id": "K_O92Hg4hutZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 50 flask.log"
      ],
      "metadata": {
        "id": "i7YEHvqchyai"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -v http://127.0.0.1:5000/ || echo \"server not running\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0a2vQDAHh0Z3",
        "outputId": "46da348b-e843-4086-df2f-f03d4448d1b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   Trying 127.0.0.1:5000...\n",
            "* connect to 127.0.0.1 port 5000 failed: Connection refused\n",
            "* Failed to connect to 127.0.0.1 port 5000 after 0 ms: Connection refused\n",
            "* Closing connection 0\n",
            "curl: (7) Failed to connect to 127.0.0.1 port 5000 after 0 ms: Connection refused\n",
            "server not running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/ultrasound_project/bus_uclm_separated/benign\n",
        "# then, for example:\n",
        "!curl -v -X POST -F \"file=@/content/ultrasound_project/bus_uclm_separated/benign/VITR_009.png\" https://subaquatic-wittingly-sharon.ngrok-free.dev/predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QsJjk4tLh5-V",
        "outputId": "08216f35-5f8a-4c17-8a40-a245c2f20998"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 85756\n",
            "-rw-r--r-- 1 root root 498328 Nov 22 13:55 ALWI_000.png\n",
            "-rw-r--r-- 1 root root 469631 Nov 22 13:55 ALWI_002.png\n",
            "-rw-r--r-- 1 root root 512794 Nov 22 13:55 ALWI_003.png\n",
            "-rw-r--r-- 1 root root 513581 Nov 22 13:55 ALWI_004.png\n",
            "-rw-r--r-- 1 root root 501996 Nov 22 13:55 ALWI_005.png\n",
            "-rw-r--r-- 1 root root 470460 Nov 22 13:55 ALWI_007.png\n",
            "-rw-r--r-- 1 root root 498615 Nov 22 13:55 ALWI_008.png\n",
            "-rw-r--r-- 1 root root 498333 Nov 22 13:55 ALWI_009.png\n",
            "-rw-r--r-- 1 root root 494466 Nov 22 13:55 ALWI_010.png\n",
            "-rw-r--r-- 1 root root 494564 Nov 22 13:55 ALWI_011.png\n",
            "-rw-r--r-- 1 root root 444846 Nov 22 13:55 ALWI_015.png\n",
            "-rw-r--r-- 1 root root 460411 Nov 22 13:55 ALWI_016.png\n",
            "-rw-r--r-- 1 root root 439896 Nov 22 13:55 ALWI_017.png\n",
            "-rw-r--r-- 1 root root 478293 Nov 22 13:55 ALWI_018.png\n",
            "-rw-r--r-- 1 root root 621122 Nov 22 13:55 ALWI_019.png\n",
            "-rw-r--r-- 1 root root 484406 Nov 22 13:55 ALWI_020.png\n",
            "-rw-r--r-- 1 root root 465961 Nov 22 13:55 ALWI_021.png\n",
            "-rw-r--r-- 1 root root 457034 Nov 22 13:55 ALWI_022.png\n",
            "-rw-r--r-- 1 root root 622611 Nov 22 13:55 ALWI_023.png\n",
            "-rw-r--r-- 1 root root 482486 Nov 22 13:55 ALWI_026.png\n",
            "-rw-r--r-- 1 root root 520390 Nov 22 13:55 ALWI_027.png\n",
            "-rw-r--r-- 1 root root 480245 Nov 22 13:55 ANFO_002.png\n",
            "-rw-r--r-- 1 root root 566057 Nov 22 13:55 ANFO_003.png\n",
            "-rw-r--r-- 1 root root 455420 Nov 22 13:55 ANFO_004.png\n",
            "-rw-r--r-- 1 root root 549256 Nov 22 13:55 ANFO_005.png\n",
            "-rw-r--r-- 1 root root 484372 Nov 22 13:55 ANFO_006.png\n",
            "-rw-r--r-- 1 root root 465995 Nov 22 13:55 ANFO_007.png\n",
            "-rw-r--r-- 1 root root 504514 Nov 22 13:55 ANFO_009.png\n",
            "-rw-r--r-- 1 root root 446827 Nov 22 13:55 ASSC_000.png\n",
            "-rw-r--r-- 1 root root 489492 Nov 22 13:55 ASSC_001.png\n",
            "-rw-r--r-- 1 root root 453404 Nov 22 13:55 ASSC_002.png\n",
            "-rw-r--r-- 1 root root 421732 Nov 22 13:55 ASSC_003.png\n",
            "-rw-r--r-- 1 root root 436254 Nov 22 13:55 ASSC_005.png\n",
            "-rw-r--r-- 1 root root 443635 Nov 22 13:55 ASSC_006.png\n",
            "-rw-r--r-- 1 root root 426659 Nov 22 13:55 ASSC_014.png\n",
            "-rw-r--r-- 1 root root 441685 Nov 22 13:55 ASSC_015.png\n",
            "-rw-r--r-- 1 root root 454912 Nov 22 13:55 ASSC_016.png\n",
            "-rw-r--r-- 1 root root 449234 Nov 22 13:55 ASSC_027.png\n",
            "-rw-r--r-- 1 root root 415530 Nov 22 13:55 ASSC_028.png\n",
            "-rw-r--r-- 1 root root 408704 Nov 22 13:55 CAWI_003.png\n",
            "-rw-r--r-- 1 root root 410325 Nov 22 13:55 CAWI_004.png\n",
            "-rw-r--r-- 1 root root 415030 Nov 22 13:55 CAWI_005.png\n",
            "-rw-r--r-- 1 root root 428453 Nov 22 13:55 CAWI_009.png\n",
            "-rw-r--r-- 1 root root 423440 Nov 22 13:55 CAWI_010.png\n",
            "-rw-r--r-- 1 root root 430567 Nov 22 13:55 CAWI_011.png\n",
            "-rw-r--r-- 1 root root 427357 Nov 22 13:55 CAWI_012.png\n",
            "-rw-r--r-- 1 root root 436780 Nov 22 13:55 CAWI_013.png\n",
            "-rw-r--r-- 1 root root 445464 Nov 22 13:55 CAWI_016.png\n",
            "-rw-r--r-- 1 root root 516454 Nov 22 13:55 CAWI_023.png\n",
            "-rw-r--r-- 1 root root 422402 Nov 22 13:55 CHVI_020.png\n",
            "-rw-r--r-- 1 root root 425439 Nov 22 13:55 CHVI_021.png\n",
            "-rw-r--r-- 1 root root 444005 Nov 22 13:55 COST_010.png\n",
            "-rw-r--r-- 1 root root 429660 Nov 22 13:55 COST_011.png\n",
            "-rw-r--r-- 1 root root 619460 Nov 22 13:55 DAPA_001.png\n",
            "-rw-r--r-- 1 root root 613521 Nov 22 13:55 DAPA_002.png\n",
            "-rw-r--r-- 1 root root 530564 Nov 22 13:55 DAPA_005.png\n",
            "-rw-r--r-- 1 root root 471032 Nov 22 13:55 DAPA_006.png\n",
            "-rw-r--r-- 1 root root 443694 Nov 22 13:55 DAPA_007.png\n",
            "-rw-r--r-- 1 root root 498991 Nov 22 13:55 DAPA_012.png\n",
            "-rw-r--r-- 1 root root 471172 Nov 22 13:55 DAPA_013.png\n",
            "-rw-r--r-- 1 root root 471119 Nov 22 13:55 DAPA_014.png\n",
            "-rw-r--r-- 1 root root 481932 Nov 22 13:55 DAPA_015.png\n",
            "-rw-r--r-- 1 root root 455081 Nov 22 13:55 DAPA_016.png\n",
            "-rw-r--r-- 1 root root 517577 Nov 22 13:55 DAPA_017.png\n",
            "-rw-r--r-- 1 root root 520704 Nov 22 13:55 DAPA_019.png\n",
            "-rw-r--r-- 1 root root 617862 Nov 22 13:55 DAPA_020.png\n",
            "-rw-r--r-- 1 root root 627375 Nov 22 13:55 DAPA_021.png\n",
            "-rw-r--r-- 1 root root 533079 Nov 22 13:55 DAPA_022.png\n",
            "-rw-r--r-- 1 root root 537373 Nov 22 13:55 DAPA_023.png\n",
            "-rw-r--r-- 1 root root 539090 Nov 22 13:55 DAPA_024.png\n",
            "-rw-r--r-- 1 root root 487818 Nov 22 13:55 DAPA_025.png\n",
            "-rw-r--r-- 1 root root 618016 Nov 22 13:55 DAPA_029.png\n",
            "-rw-r--r-- 1 root root 537207 Nov 22 13:55 DAPA_031.png\n",
            "-rw-r--r-- 1 root root 613979 Nov 22 13:55 DAPA_032.png\n",
            "-rw-r--r-- 1 root root 523886 Nov 22 13:55 DAPA_033.png\n",
            "-rw-r--r-- 1 root root 617811 Nov 22 13:55 DAPA_034.png\n",
            "-rw-r--r-- 1 root root 614507 Nov 22 13:55 DAPA_035.png\n",
            "-rw-r--r-- 1 root root 524779 Nov 22 13:55 DAPA_038.png\n",
            "-rw-r--r-- 1 root root 429490 Nov 22 13:55 FLBA_017.png\n",
            "-rw-r--r-- 1 root root 541981 Nov 22 13:55 FUHI_007.png\n",
            "-rw-r--r-- 1 root root 465994 Nov 22 13:55 HESN_002.png\n",
            "-rw-r--r-- 1 root root 458760 Nov 22 13:55 HESN_003.png\n",
            "-rw-r--r-- 1 root root 464697 Nov 22 13:55 HESN_004.png\n",
            "-rw-r--r-- 1 root root 491809 Nov 22 13:55 HESN_005.png\n",
            "-rw-r--r-- 1 root root 539253 Nov 22 13:55 HUBL_015.png\n",
            "-rw-r--r-- 1 root root 498515 Nov 22 13:55 KIFO_003.png\n",
            "-rw-r--r-- 1 root root 557765 Nov 22 13:55 KIFO_004.png\n",
            "-rw-r--r-- 1 root root 529667 Nov 22 13:55 KIFO_005.png\n",
            "-rw-r--r-- 1 root root 532981 Nov 22 13:55 KIFO_006.png\n",
            "-rw-r--r-- 1 root root 514736 Nov 22 13:55 KIFO_007.png\n",
            "-rw-r--r-- 1 root root 619118 Nov 22 13:55 KIFO_008.png\n",
            "-rw-r--r-- 1 root root 613315 Nov 22 13:55 KIFO_009.png\n",
            "-rw-r--r-- 1 root root 491749 Nov 22 13:55 MENE_017.png\n",
            "-rw-r--r-- 1 root root 423551 Nov 22 13:55 NIRO_000.png\n",
            "-rw-r--r-- 1 root root 525792 Nov 22 13:55 ORPE_001.png\n",
            "-rw-r--r-- 1 root root 533503 Nov 22 13:55 ORPE_011.png\n",
            "-rw-r--r-- 1 root root 491767 Nov 22 13:55 ORPE_014.png\n",
            "-rw-r--r-- 1 root root 582808 Nov 22 13:55 ORPE_015.png\n",
            "-rw-r--r-- 1 root root 501992 Nov 22 13:55 ORPE_017.png\n",
            "-rw-r--r-- 1 root root 539196 Nov 22 13:55 ORPE_019.png\n",
            "-rw-r--r-- 1 root root 630356 Nov 22 13:55 ORPE_020.png\n",
            "-rw-r--r-- 1 root root 455093 Nov 22 13:55 ORPE_021.png\n",
            "-rw-r--r-- 1 root root 545672 Nov 22 13:55 ORPE_022.png\n",
            "-rw-r--r-- 1 root root 546163 Nov 22 13:55 ORPE_023.png\n",
            "-rw-r--r-- 1 root root 612283 Nov 22 13:55 OSCU_012.png\n",
            "-rw-r--r-- 1 root root 601977 Nov 22 13:55 OSCU_013.png\n",
            "-rw-r--r-- 1 root root 477571 Nov 22 13:55 OSCU_014.png\n",
            "-rw-r--r-- 1 root root 484151 Nov 22 13:55 OSCU_015.png\n",
            "-rw-r--r-- 1 root root 481065 Nov 22 13:55 OSCU_016.png\n",
            "-rw-r--r-- 1 root root 471099 Nov 22 13:55 OSCU_017.png\n",
            "-rw-r--r-- 1 root root 508254 Nov 22 13:55 OSCU_019.png\n",
            "-rw-r--r-- 1 root root 508293 Nov 22 13:55 OSCU_020.png\n",
            "-rw-r--r-- 1 root root 508688 Nov 22 13:55 OSCU_021.png\n",
            "-rw-r--r-- 1 root root 507570 Nov 22 13:55 OSCU_022.png\n",
            "-rw-r--r-- 1 root root 499983 Nov 22 13:55 OSCU_023.png\n",
            "-rw-r--r-- 1 root root 495469 Nov 22 13:55 PLBA_001.png\n",
            "-rw-r--r-- 1 root root 481793 Nov 22 13:55 PLBA_002.png\n",
            "-rw-r--r-- 1 root root 514208 Nov 22 13:55 PLBA_003.png\n",
            "-rw-r--r-- 1 root root 492016 Nov 22 13:55 PLBA_008.png\n",
            "-rw-r--r-- 1 root root 516817 Nov 22 13:55 PLBA_009.png\n",
            "-rw-r--r-- 1 root root 500635 Nov 22 13:55 PLBA_010.png\n",
            "-rw-r--r-- 1 root root 471300 Nov 22 13:55 PLBA_013.png\n",
            "-rw-r--r-- 1 root root 484130 Nov 22 13:55 PLBA_014.png\n",
            "-rw-r--r-- 1 root root 530721 Nov 22 13:55 PLBA_018.png\n",
            "-rw-r--r-- 1 root root 505778 Nov 22 13:55 PLBA_019.png\n",
            "-rw-r--r-- 1 root root 524138 Nov 22 13:55 PLBA_024.png\n",
            "-rw-r--r-- 1 root root 508926 Nov 22 13:55 POFR_011.png\n",
            "-rw-r--r-- 1 root root 617899 Nov 22 13:55 POFR_012.png\n",
            "-rw-r--r-- 1 root root 617313 Nov 22 13:55 POFR_013.png\n",
            "-rw-r--r-- 1 root root 518548 Nov 22 13:55 POFR_017.png\n",
            "-rw-r--r-- 1 root root 519165 Nov 22 13:55 POFR_022.png\n",
            "-rw-r--r-- 1 root root 433125 Nov 22 13:55 RARE_000.png\n",
            "-rw-r--r-- 1 root root 551094 Nov 22 13:55 RARE_001.png\n",
            "-rw-r--r-- 1 root root 555112 Nov 22 13:55 RARE_002.png\n",
            "-rw-r--r-- 1 root root 555721 Nov 22 13:55 RARE_003.png\n",
            "-rw-r--r-- 1 root root 552251 Nov 22 13:55 RARE_004.png\n",
            "-rw-r--r-- 1 root root 467496 Nov 22 13:55 SECH_008.png\n",
            "-rw-r--r-- 1 root root 472440 Nov 22 13:55 SECH_009.png\n",
            "-rw-r--r-- 1 root root 461770 Nov 22 13:55 SECH_010.png\n",
            "-rw-r--r-- 1 root root 460876 Nov 22 13:55 SECH_011.png\n",
            "-rw-r--r-- 1 root root 455866 Nov 22 13:55 SECH_012.png\n",
            "-rw-r--r-- 1 root root 622649 Nov 22 13:55 SHST_005.png\n",
            "-rw-r--r-- 1 root root 613887 Nov 22 13:55 SHST_006.png\n",
            "-rw-r--r-- 1 root root 515951 Nov 22 13:55 SHST_008.png\n",
            "-rw-r--r-- 1 root root 489690 Nov 22 13:55 SHST_009.png\n",
            "-rw-r--r-- 1 root root 517638 Nov 22 13:55 SHST_011.png\n",
            "-rw-r--r-- 1 root root 491871 Nov 22 13:55 STSP_001.png\n",
            "-rw-r--r-- 1 root root 600534 Nov 22 13:55 STSP_002.png\n",
            "-rw-r--r-- 1 root root 433885 Nov 22 13:55 STSP_003.png\n",
            "-rw-r--r-- 1 root root 438865 Nov 22 13:55 STSP_004.png\n",
            "-rw-r--r-- 1 root root 498280 Nov 22 13:55 STSP_018.png\n",
            "-rw-r--r-- 1 root root 500875 Nov 22 13:55 STSP_019.png\n",
            "-rw-r--r-- 1 root root 506765 Nov 22 13:55 STSP_020.png\n",
            "-rw-r--r-- 1 root root 521401 Nov 22 13:55 STSP_026.png\n",
            "-rw-r--r-- 1 root root 511066 Nov 22 13:55 TOCI_003.png\n",
            "-rw-r--r-- 1 root root 506155 Nov 22 13:55 TOCI_005.png\n",
            "-rw-r--r-- 1 root root 515759 Nov 22 13:55 TOCI_008.png\n",
            "-rw-r--r-- 1 root root 521800 Nov 22 13:55 TOCI_012.png\n",
            "-rw-r--r-- 1 root root 529026 Nov 22 13:55 TOCI_013.png\n",
            "-rw-r--r-- 1 root root 502961 Nov 22 13:55 TOCI_020.png\n",
            "-rw-r--r-- 1 root root 510631 Nov 22 13:55 TOCI_021.png\n",
            "-rw-r--r-- 1 root root 490364 Nov 22 13:55 TOCI_022.png\n",
            "-rw-r--r-- 1 root root 514403 Nov 22 13:55 TOCI_023.png\n",
            "-rw-r--r-- 1 root root 507249 Nov 22 13:55 TOCI_024.png\n",
            "-rw-r--r-- 1 root root 484291 Nov 22 13:55 TOCI_031.png\n",
            "-rw-r--r-- 1 root root 497159 Nov 22 13:55 VITR_001.png\n",
            "-rw-r--r-- 1 root root 498817 Nov 22 13:55 VITR_003.png\n",
            "-rw-r--r-- 1 root root 499438 Nov 22 13:55 VITR_004.png\n",
            "-rw-r--r-- 1 root root 483487 Nov 22 13:55 VITR_005.png\n",
            "-rw-r--r-- 1 root root 479353 Nov 22 13:55 VITR_009.png\n",
            "-rw-r--r-- 1 root root 477325 Nov 22 13:55 VITR_010.png\n",
            "-rw-r--r-- 1 root root 432340 Nov 22 13:55 VITR_011.png\n",
            "-rw-r--r-- 1 root root 436275 Nov 22 13:55 VITR_012.png\n",
            "-rw-r--r-- 1 root root 463968 Nov 22 13:55 VITR_028.png\n",
            "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
            "*   Trying 54.183.107.205:443...\n",
            "* Connected to subaquatic-wittingly-sharon.ngrok-free.dev (54.183.107.205) port 443 (#0)\n",
            "* ALPN, offering h2\n",
            "* ALPN, offering http/1.1\n",
            "*  CAfile: /etc/ssl/certs/ca-certificates.crt\n",
            "*  CApath: /etc/ssl/certs\n",
            "* TLSv1.0 (OUT), TLS header, Certificate Status (22):\n",
            "* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n",
            "* TLSv1.2 (IN), TLS header, Certificate Status (22):\n",
            "* TLSv1.3 (IN), TLS handshake, Server hello (2):\n",
            "* TLSv1.2 (IN), TLS header, Finished (20):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (IN), TLS handshake, Certificate (11):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (IN), TLS handshake, CERT verify (15):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (IN), TLS handshake, Finished (20):\n",
            "* TLSv1.2 (OUT), TLS header, Finished (20):\n",
            "* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (OUT), TLS handshake, Finished (20):\n",
            "* SSL connection using TLSv1.3 / TLS_AES_128_GCM_SHA256\n",
            "* ALPN, server accepted to use h2\n",
            "* Server certificate:\n",
            "*  subject: CN=*.ngrok-free.dev\n",
            "*  start date: Sep 30 18:02:43 2025 GMT\n",
            "*  expire date: Dec 29 18:02:42 2025 GMT\n",
            "*  subjectAltName: host \"subaquatic-wittingly-sharon.ngrok-free.dev\" matched cert's \"*.ngrok-free.dev\"\n",
            "*  issuer: C=US; O=Let's Encrypt; CN=E7\n",
            "*  SSL certificate verify ok.\n",
            "* Using HTTP2, server supports multiplexing\n",
            "* Connection state changed (HTTP/2 confirmed)\n",
            "* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* Using Stream ID: 1 (easy handle 0x5966028beeb0)\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "> POST /predict HTTP/2\n",
            "> Host: subaquatic-wittingly-sharon.ngrok-free.dev\n",
            "> user-agent: curl/7.81.0\n",
            "> accept: */*\n",
            "> content-length: 479542\n",
            "> content-type: multipart/form-data; boundary=------------------------11c939f305fc69e7\n",
            "> \n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* Connection state changed (MAX_CONCURRENT_STREAMS == 250)!\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* We are completely uploaded and fine\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-22T14:00:57+0000 lvl=warn msg=\"failed to open private leg\" id=72541d4b9213 privaddr=localhost:5000 err=\"dial tcp [::1]:5000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "< HTTP/2 502 \n",
            "< content-type: text/html\n",
            "< ngrok-error-code: ERR_NGROK_8012\n",
            "< referrer-policy: no-referrer\n",
            "< content-length: 2684\n",
            "< date: Sat, 22 Nov 2025 14:00:57 GMT\n",
            "< \n",
            "* TLSv1.2 (IN), TLS header, Supplemental data (23):\n",
            "<!DOCTYPE html>\n",
            "<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <meta name=\"author\" content=\"ngrok\">\n",
            "    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n",
            "    <link href=\"https://ngrok.com/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
            "    <meta name=\"robots\" content=\"noindex, nofollow\">\n",
            "    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n",
            "    <noscript>Traffic successfully made it to the ngrok agent, but the agent failed to establish a connection to the upstream web service at localhost:5000. (ERR_NGROK_8012)</noscript>\n",
            "    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n",
            "  </head>\n",
            "  <body class=\"h-full\" id=\"ngrok\">\n",
            "    <div id=\"root\" data-payload=\"eyJhZGRyIjoibG9jYWxob3N0OjUwMDAiLCJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiI4MDEyIiwiZXJyb3JUZXh0IjoiZGlhbCB0Y3AgWzo6MV06NTAwMDogY29ubmVjdDogY29ubmVjdGlvbiByZWZ1c2VkIiwibWVzc2FnZSI6IlRyYWZmaWMgc3VjY2Vzc2Z1bGx5IG1hZGUgaXQgdG8gdGhlIG5ncm9rIGFnZW50LCBidXQgdGhlIGFnZW50IGZhaWxlZCB0byBlc3RhYmxpc2ggYSBjb25uZWN0aW9uIHRvIHRoZSB1cHN0cmVhbSB3ZWIgc2VydmljZSBhdCBsb2NhbGhvc3Q6NTAwMC4iLCJzY2hlbWUiOiJodHRwIiwidGl0bGUiOiJCYWQgR2F0ZXdheSJ9\"></div>\n",
            "  </body>\n",
            "</html>\n",
            "* Closing connection 0\n",
            "* TLSv1.2 (OUT), TLS header, Supplemental data (23):\n",
            "* TLSv1.3 (OUT), TLS alert, close notify (256):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST -F \"file=@/content/ultrasound_project/bus_uclm_separated/benign/ALWI_000.png\" https://subaquatic-wittingly-sharon.ngrok-free.dev/predict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eOKez3HkiAqx",
        "outputId": "c3d0bd96-c99e-4205-ae70-e9deb1f0eb61"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-22T14:00:58+0000 lvl=warn msg=\"failed to open private leg\" id=44c4a0198376 privaddr=localhost:5000 err=\"dial tcp [::1]:5000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <meta name=\"author\" content=\"ngrok\">\n",
            "    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n",
            "    <link href=\"https://ngrok.com/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
            "    <meta name=\"robots\" content=\"noindex, nofollow\">\n",
            "    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n",
            "    <noscript>Traffic successfully made it to the ngrok agent, but the agent failed to establish a connection to the upstream web service at localhost:5000. (ERR_NGROK_8012)</noscript>\n",
            "    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n",
            "  </head>\n",
            "  <body class=\"h-full\" id=\"ngrok\">\n",
            "    <div id=\"root\" data-payload=\"eyJhZGRyIjoibG9jYWxob3N0OjUwMDAiLCJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiI4MDEyIiwiZXJyb3JUZXh0IjoiZGlhbCB0Y3AgWzo6MV06NTAwMDogY29ubmVjdDogY29ubmVjdGlvbiByZWZ1c2VkIiwibWVzc2FnZSI6IlRyYWZmaWMgc3VjY2Vzc2Z1bGx5IG1hZGUgaXQgdG8gdGhlIG5ncm9rIGFnZW50LCBidXQgdGhlIGFnZW50IGZhaWxlZCB0byBlc3RhYmxpc2ggYSBjb25uZWN0aW9uIHRvIHRoZSB1cHN0cmVhbSB3ZWIgc2VydmljZSBhdCBsb2NhbGhvc3Q6NTAwMC4iLCJzY2hlbWUiOiJodHRwIiwidGl0bGUiOiJCYWQgR2F0ZXdheSJ9\"></div>\n",
            "  </body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "mkdir -p templates\n",
        "cat > templates/index.html <<'HTML'\n",
        "<!doctype html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\" />\n",
        "  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
        "  <title>Ultrasound Classifier</title>\n",
        "  <style>\n",
        "    body { font-family: Arial, Helvetica, sans-serif; max-width:800px; margin:40px auto; line-height:1.5; }\n",
        "    .card { border:1px solid #eee; padding:20px; border-radius:8px; box-shadow:0 2px 6px rgba(0,0,0,0.05); }\n",
        "    input[type=file] { display:block; margin-top:10px; }\n",
        "    button { background:#1976d2;color:#fff;border:none;padding:10px 16px;border-radius:6px; cursor:pointer }\n",
        "    .result { margin-top:18px; font-weight:600; }\n",
        "    .small { font-size:0.9rem; color:#666; }\n",
        "    img.preview { max-width:320px; display:block; margin-top:12px; border-radius:6px; }\n",
        "    footer { margin-top:26px; font-size:0.9rem; color:#444; }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <h2>Breast Ultrasound Classifier</h2>\n",
        "  <div class=\"card\">\n",
        "    <p class=\"small\">Upload an ultrasound image. The model will return a predicted class and confidence score.</p>\n",
        "\n",
        "    <form id=\"uploadForm\" method=\"post\" enctype=\"multipart/form-data\" action=\"/predict\">\n",
        "      <input type=\"file\" name=\"file\" id=\"fileInput\" accept=\"image/*\" required />\n",
        "      <button type=\"submit\">Upload & Predict</button>\n",
        "    </form>\n",
        "\n",
        "    <div id=\"output\" class=\"result\" style=\"display:none;\"></div>\n",
        "    <img id=\"preview\" class=\"preview\" src=\"\" style=\"display:none;\" />\n",
        "\n",
        "    <div style=\"margin-top:14px;\">\n",
        "      <a href=\"/paper\" target=\"_blank\">📄 View uploaded manuscript (paper)</a>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <footer>\n",
        "    Tip: you can also call the direct API at <code>/predict</code> (multipart/form-data).\n",
        "  </footer>\n",
        "\n",
        "  <script>\n",
        "    const form = document.getElementById('uploadForm');\n",
        "    const fileInput = document.getElementById('fileInput');\n",
        "    const output = document.getElementById('output');\n",
        "    const preview = document.getElementById('preview');\n",
        "\n",
        "    fileInput.addEventListener('change', (e) => {\n",
        "      const f = e.target.files[0];\n",
        "      if (!f) return;\n",
        "      const url = URL.createObjectURL(f);\n",
        "      preview.src = url;\n",
        "      preview.style.display = 'block';\n",
        "    });\n",
        "\n",
        "    form.addEventListener('submit', async (e) => {\n",
        "      e.preventDefault();\n",
        "      output.style.display = 'none';\n",
        "      const formData = new FormData(form);\n",
        "      output.textContent = 'Predicting...';\n",
        "      output.style.display = 'block';\n",
        "      try {\n",
        "        const res = await fetch('/predict', { method: 'POST', body: formData });\n",
        "        const json = await res.json();\n",
        "        if (res.ok) {\n",
        "          output.innerHTML = `Prediction: <strong>${json.class}</strong> — Confidence: <strong>${(json.confidence*100).toFixed(1)}%</strong>`;\n",
        "        } else {\n",
        "          output.innerHTML = `Error: ${json.error || res.statusText}`;\n",
        "        }\n",
        "      } catch (err) {\n",
        "        output.innerHTML = `Request failed: ${err}`;\n",
        "      }\n",
        "    });\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "HTML\n",
        "echo \"Created templates/index.html\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "irHwCy-uiCL_",
        "outputId": "b9f38fdd-ffd4-4cd3-ba72-731e5c0edf48"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created templates/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > app.py <<'PY'\n",
        "# app.py — Flask web UI + prediction endpoint (rebuilds model and loads weights)\n",
        "from flask import Flask, request, jsonify, render_template, send_file, redirect, url_for\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io, os, pathlib\n",
        "\n",
        "# Config\n",
        "IMG_SIZE = 224\n",
        "RNN_UNITS = 256\n",
        "NUM_CLASSES = 3\n",
        "WEIGHTS_H5 = \"best_transfer_vecalpha.h5\"   # saved during training\n",
        "KERAS_FILE = \"transfer_mobilenet_vecalpha.keras\"\n",
        "PAPER_PATH = \"/mnt/data/952 Manuscript (1).pdf\"  # your uploaded manuscript (served at /paper)\n",
        "\n",
        "# Build model function (same architecture as training)\n",
        "def build_transfer_model(img_size=IMG_SIZE, rnn_units=RNN_UNITS, num_classes=NUM_CLASSES):\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.05),\n",
        "        layers.RandomContrast(0.05),\n",
        "    ], name=\"data_augment\")\n",
        "\n",
        "    inp = Input(shape=(img_size, img_size, 3), name=\"image_input\")\n",
        "    x = data_augmentation(inp)\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x * 255.0)\n",
        "    base = tf.keras.applications.MobileNetV2(input_shape=(img_size,img_size,3), include_top=False, weights='imagenet', pooling='avg')\n",
        "    base.trainable = False\n",
        "    features = base(x)\n",
        "\n",
        "    projC = layers.Dense(rnn_units, name=\"projectC\")(features)\n",
        "    H_in = layers.Reshape((1, rnn_units), name=\"rnn_input\")(projC)\n",
        "    H_t = layers.GRU(rnn_units, return_sequences=False, name=\"gru\")(H_in)\n",
        "\n",
        "    concat = layers.Concatenate(name=\"concat_HC\")([H_t, projC])\n",
        "    alpha_vec = layers.Dense(rnn_units, activation=\"sigmoid\", name=\"fusion_alpha_vec\")(concat)\n",
        "\n",
        "    alpha_mul_H = layers.Multiply(name=\"alpha_mul_H\")([alpha_vec, H_t])\n",
        "    one_minus_alpha = layers.Lambda(lambda z: 1.0 - z, name=\"one_minus_alpha\")(alpha_vec)\n",
        "    alpha_mul_C = layers.Multiply(name=\"alpha_mul_C\")([one_minus_alpha, projC])\n",
        "    F = layers.Add(name=\"fusion_add\")([alpha_mul_H, alpha_mul_C])\n",
        "\n",
        "    x = layers.LayerNormalization(name=\"head_ln\")(F)\n",
        "    x = layers.Dense(256, activation=\"relu\", name=\"head_fc\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    logits = layers.Dense(num_classes, name=\"logits\")(x)\n",
        "    outputs = layers.Activation(\"softmax\", dtype=\"float32\", name=\"softmax_out\")(logits)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=outputs, name=\"MobileNetV2_TransRNN_vecalpha_infer\")\n",
        "    return model\n",
        "\n",
        "# Create app and model\n",
        "app = Flask(__name__, template_folder='templates')\n",
        "model = build_transfer_model()\n",
        "# load weights robustly\n",
        "if os.path.exists(WEIGHTS_H5):\n",
        "    try:\n",
        "        model.load_weights(WEIGHTS_H5)\n",
        "        print(\"Loaded H5 weights into model.\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load weights via load_weights(); trying full-load fallback.\", e)\n",
        "        if os.path.exists(KERAS_FILE):\n",
        "            whole = tf.keras.models.load_model(KERAS_FILE, compile=False)\n",
        "            model.set_weights(whole.get_weights())\n",
        "            print(\"Loaded weights from .keras fallback.\")\n",
        "        else:\n",
        "            raise\n",
        "elif os.path.exists(KERAS_FILE):\n",
        "    whole = tf.keras.models.load_model(KERAS_FILE, compile=False)\n",
        "    model.set_weights(whole.get_weights())\n",
        "    print(\"Loaded weights from .keras file.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"No model file found. Put best_transfer_vecalpha.h5 or transfer_mobilenet_vecalpha.keras in working dir.\")\n",
        "\n",
        "# freeze for inference\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# class order used in training\n",
        "CLASSES = [\"benign\", \"malign\", \"normal\"]\n",
        "\n",
        "def preprocess_image_bytes(b):\n",
        "    img = Image.open(io.BytesIO(b)).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "    arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\":\"no file provided\"}), 400\n",
        "    f = request.files['file']\n",
        "    try:\n",
        "        b = f.read()\n",
        "        x = preprocess_image_bytes(b)\n",
        "        preds = model.predict(x)\n",
        "        idx = int(np.argmax(preds[0]))\n",
        "        return jsonify({\"class\": CLASSES[idx], \"confidence\": float(preds[0, idx])})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# serve the uploaded manuscript as a download/view link.\n",
        "@app.route(\"/paper\", methods=[\"GET\"])\n",
        "def paper():\n",
        "    # send_file will stream the PDF back to the client\n",
        "    if os.path.exists(PAPER_PATH):\n",
        "        return send_file(PAPER_PATH, as_attachment=False)\n",
        "    return redirect(\"/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Port 5000 is expected by ngrok setup\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "PY\n",
        "echo \"Wrote app.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZxjEA60KiHf2",
        "outputId": "3b9a1d62-3c90-416c-91ce-0cdb402b6c9d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python app.py > flask.log 2>&1 &\n",
        "!sleep 1\n",
        "!tail -n 80 flask.log\n"
      ],
      "metadata": {
        "id": "z7qFHPIdiLyH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "858d1983-cb51-4483-faf9-102c0d6b5c1d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-22 14:00:59.348906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763820059.484613    3501 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763820059.522232    3501 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763820059.607812    3501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763820059.607865    3501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763820059.607871    3501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763820059.607876    3501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "t = ngrok.connect(5000, \"http\")\n",
        "print(\"Public URL:\", t.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kuWkRrasiPcY",
        "outputId": "a5937eda-6449-45c6-a745-a7d8acfb1d58"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://subaquatic-wittingly-sharon.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultrasound_project/bus_uclm_separated/benign | sed -n '1,200p'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9aHIPY3Bidp_",
        "outputId": "4a1a5158-51be-4e98-898a-7568eeb02290"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALWI_000.png\n",
            "ALWI_002.png\n",
            "ALWI_003.png\n",
            "ALWI_004.png\n",
            "ALWI_005.png\n",
            "ALWI_007.png\n",
            "ALWI_008.png\n",
            "ALWI_009.png\n",
            "ALWI_010.png\n",
            "ALWI_011.png\n",
            "ALWI_015.png\n",
            "ALWI_016.png\n",
            "ALWI_017.png\n",
            "ALWI_018.png\n",
            "ALWI_019.png\n",
            "ALWI_020.png\n",
            "ALWI_021.png\n",
            "ALWI_022.png\n",
            "ALWI_023.png\n",
            "ALWI_026.png\n",
            "ALWI_027.png\n",
            "ANFO_002.png\n",
            "ANFO_003.png\n",
            "ANFO_004.png\n",
            "ANFO_005.png\n",
            "ANFO_006.png\n",
            "ANFO_007.png\n",
            "ANFO_009.png\n",
            "ASSC_000.png\n",
            "ASSC_001.png\n",
            "ASSC_002.png\n",
            "ASSC_003.png\n",
            "ASSC_005.png\n",
            "ASSC_006.png\n",
            "ASSC_014.png\n",
            "ASSC_015.png\n",
            "ASSC_016.png\n",
            "ASSC_027.png\n",
            "ASSC_028.png\n",
            "CAWI_003.png\n",
            "CAWI_004.png\n",
            "CAWI_005.png\n",
            "CAWI_009.png\n",
            "CAWI_010.png\n",
            "CAWI_011.png\n",
            "CAWI_012.png\n",
            "CAWI_013.png\n",
            "CAWI_016.png\n",
            "CAWI_023.png\n",
            "CHVI_020.png\n",
            "CHVI_021.png\n",
            "COST_010.png\n",
            "COST_011.png\n",
            "DAPA_001.png\n",
            "DAPA_002.png\n",
            "DAPA_005.png\n",
            "DAPA_006.png\n",
            "DAPA_007.png\n",
            "DAPA_012.png\n",
            "DAPA_013.png\n",
            "DAPA_014.png\n",
            "DAPA_015.png\n",
            "DAPA_016.png\n",
            "DAPA_017.png\n",
            "DAPA_019.png\n",
            "DAPA_020.png\n",
            "DAPA_021.png\n",
            "DAPA_022.png\n",
            "DAPA_023.png\n",
            "DAPA_024.png\n",
            "DAPA_025.png\n",
            "DAPA_029.png\n",
            "DAPA_031.png\n",
            "DAPA_032.png\n",
            "DAPA_033.png\n",
            "DAPA_034.png\n",
            "DAPA_035.png\n",
            "DAPA_038.png\n",
            "FLBA_017.png\n",
            "FUHI_007.png\n",
            "HESN_002.png\n",
            "HESN_003.png\n",
            "HESN_004.png\n",
            "HESN_005.png\n",
            "HUBL_015.png\n",
            "KIFO_003.png\n",
            "KIFO_004.png\n",
            "KIFO_005.png\n",
            "KIFO_006.png\n",
            "KIFO_007.png\n",
            "KIFO_008.png\n",
            "KIFO_009.png\n",
            "MENE_017.png\n",
            "NIRO_000.png\n",
            "ORPE_001.png\n",
            "ORPE_011.png\n",
            "ORPE_014.png\n",
            "ORPE_015.png\n",
            "ORPE_017.png\n",
            "ORPE_019.png\n",
            "ORPE_020.png\n",
            "ORPE_021.png\n",
            "ORPE_022.png\n",
            "ORPE_023.png\n",
            "OSCU_012.png\n",
            "OSCU_013.png\n",
            "OSCU_014.png\n",
            "OSCU_015.png\n",
            "OSCU_016.png\n",
            "OSCU_017.png\n",
            "OSCU_019.png\n",
            "OSCU_020.png\n",
            "OSCU_021.png\n",
            "OSCU_022.png\n",
            "OSCU_023.png\n",
            "PLBA_001.png\n",
            "PLBA_002.png\n",
            "PLBA_003.png\n",
            "PLBA_008.png\n",
            "PLBA_009.png\n",
            "PLBA_010.png\n",
            "PLBA_013.png\n",
            "PLBA_014.png\n",
            "PLBA_018.png\n",
            "PLBA_019.png\n",
            "PLBA_024.png\n",
            "POFR_011.png\n",
            "POFR_012.png\n",
            "POFR_013.png\n",
            "POFR_017.png\n",
            "POFR_022.png\n",
            "RARE_000.png\n",
            "RARE_001.png\n",
            "RARE_002.png\n",
            "RARE_003.png\n",
            "RARE_004.png\n",
            "SECH_008.png\n",
            "SECH_009.png\n",
            "SECH_010.png\n",
            "SECH_011.png\n",
            "SECH_012.png\n",
            "SHST_005.png\n",
            "SHST_006.png\n",
            "SHST_008.png\n",
            "SHST_009.png\n",
            "SHST_011.png\n",
            "STSP_001.png\n",
            "STSP_002.png\n",
            "STSP_003.png\n",
            "STSP_004.png\n",
            "STSP_018.png\n",
            "STSP_019.png\n",
            "STSP_020.png\n",
            "STSP_026.png\n",
            "TOCI_003.png\n",
            "TOCI_005.png\n",
            "TOCI_008.png\n",
            "TOCI_012.png\n",
            "TOCI_013.png\n",
            "TOCI_020.png\n",
            "TOCI_021.png\n",
            "TOCI_022.png\n",
            "TOCI_023.png\n",
            "TOCI_024.png\n",
            "TOCI_031.png\n",
            "VITR_001.png\n",
            "VITR_003.png\n",
            "VITR_004.png\n",
            "VITR_005.png\n",
            "VITR_009.png\n",
            "VITR_010.png\n",
            "VITR_011.png\n",
            "VITR_012.png\n",
            "VITR_028.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST -F \"file=@/content/ultrasound_project/bus_uclm_separated/benign/VITR_028.png\" https://subaquatic-wittingly-sharon.ngrok-free.dev/predict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6CPBrLjPijNt",
        "outputId": "fe6d103b-c475-428c-f94e-c03974b13371"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-22T14:01:01+0000 lvl=warn msg=\"failed to open private leg\" id=6e7e0ff96713 privaddr=localhost:5000 err=\"dial tcp [::1]:5000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <meta name=\"author\" content=\"ngrok\">\n",
            "    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n",
            "    <link href=\"https://ngrok.com/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
            "    <meta name=\"robots\" content=\"noindex, nofollow\">\n",
            "    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n",
            "    <noscript>Traffic successfully made it to the ngrok agent, but the agent failed to establish a connection to the upstream web service at localhost:5000. (ERR_NGROK_8012)</noscript>\n",
            "    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n",
            "  </head>\n",
            "  <body class=\"h-full\" id=\"ngrok\">\n",
            "    <div id=\"root\" data-payload=\"eyJhZGRyIjoibG9jYWxob3N0OjUwMDAiLCJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiI4MDEyIiwiZXJyb3JUZXh0IjoiZGlhbCB0Y3AgWzo6MV06NTAwMDogY29ubmVjdDogY29ubmVjdGlvbiByZWZ1c2VkIiwibWVzc2FnZSI6IlRyYWZmaWMgc3VjY2Vzc2Z1bGx5IG1hZGUgaXQgdG8gdGhlIG5ncm9rIGFnZW50LCBidXQgdGhlIGFnZW50IGZhaWxlZCB0byBlc3RhYmxpc2ggYSBjb25uZWN0aW9uIHRvIHRoZSB1cHN0cmVhbSB3ZWIgc2VydmljZSBhdCBsb2NhbGhvc3Q6NTAwMC4iLCJzY2hlbWUiOiJodHRwIiwidGl0bGUiOiJCYWQgR2F0ZXdheSJ9\"></div>\n",
            "  </body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ss -ltnp | grep :5000 || netstat -ltnp 2>/dev/null | grep :5000 || echo \"no listener on :5000\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Npy-uKF02TFi",
        "outputId": "47361c46-e8c7-44d3-8511-a39414dd4b12"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no listener on :5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 1234 || echo \"graceful kill failed\"\n",
        "!sleep 1\n",
        "!ps aux | grep -E \"python|app.py\" | sed -n '1,200p'\n",
        "# if still there, force kill:\n",
        "!kill -9 1234\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EoYJpD-z2XTC",
        "outputId": "d048fb70-9073-4512-f45e-f634abd6de43"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: kill: (1234) - No such process\n",
            "graceful kill failed\n",
            "root          64  2.7  0.0      0     0 ?        Z    13:51   0:15 [python3] <defunct>\n",
            "root          65  0.3  0.5  92968 72224 ?        S    13:51   0:02 python3 /usr/local/bin/colab-fileshim.py\n",
            "root         110  1.0  1.1 401256 147728 ?       Sl   13:51   0:05 /usr/bin/python3 /usr/local/bin/jupyter-server --debug --transport=\"ipc\" --ip=172.28.0.12 --ServerApp.token= --port=9000 --FileContentsManager.root_dir=/ --FileContentsManager.allow_hidden=True --ServerApp.log_format=\"|%(levelname)s|%(message)s\" --ServerApp.iopub_data_rate_limit=1e10 --MappingKernelManager.root_dir=/content\n",
            "root         505 98.9 16.7 12529768 2229488 ?    Ssl  13:53   7:37 /usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-f7773d41-09c0-45da-95c5-ff89728ecc1f.json\n",
            "root        3333  0.0  0.0   4364  3164 ?        S    14:00   0:00 bash -c tail -n +0 -F \"/root/.config/Google/DriveFS/Logs/drive_fs.txt\" | python3 /opt/google/drive/drive-filter.py > \"/root/.config/Google/DriveFS/Logs/timeouts.txt\" \n",
            "root        3339  0.1  0.1  23276 14736 ?        S    14:00   0:00 python3 /opt/google/drive/drive-filter.py\n",
            "root        3428  1.4  0.1 1275476 23088 ?       Sl   14:00   0:00 /usr/colab/bin/language_service --lsp_search_dirs=/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages --language_services_request_root_url=http://172.28.0.1:8013/ --language_services_request_timeout=30s -- node /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:c5097d06fd932168da039d8e3b2fdab084d73cd3c9\n",
            "root        3459 38.3  3.2 1348196 427972 ?      Rl   14:00   0:04 python3 app.py\n",
            "root        3501 31.5  3.0 1321636 403544 ?      Rl   14:00   0:01 python3 app.py\n",
            "root        3531 29.7  2.7 1287072 368572 ?      Rl   14:00   0:01 python3 app.py\n",
            "root        3565  0.0  0.0   7376  3544 ?        S    14:01   0:00 /bin/bash -c ps aux | grep -E \"python|app.py\" | sed -n '1,200p'\n",
            "root        3567  0.0  0.0   6620  2384 ?        S    14:01   0:00 grep -E python|app.py\n",
            "/bin/bash: line 1: kill: (1234) - No such process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python app.py > flask.log 2>&1 &\n",
        "!sleep 1\n",
        "!tail -n 80 flask.log\n"
      ],
      "metadata": {
        "id": "DMmq3P84jBmo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "t = ngrok.connect(5000, \"http\")\n",
        "print(\"Public URL:\", t.public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "krcseeIzjE2a",
        "outputId": "e19e5c8d-501b-4457-c705-cff77c5b6a2e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://subaquatic-wittingly-sharon.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok\n"
      ],
      "metadata": {
        "id": "XqWRdTkLzgAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b93c17cc-9e11-400e-8b98-4668615a71f7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"35jpcVLkNK0h8mmLNzjk9iw3ZEn_7crpBi2zn69wXhavuAkFE\")\n"
      ],
      "metadata": {
        "id": "c-u99Y1O3XVp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p templates static\n"
      ],
      "metadata": {
        "id": "ThH5d2Aj3oDF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Breast Ultrasound Classifier</title>\n",
        "    <link rel=\"stylesheet\"\n",
        "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\">\n",
        "</head>\n",
        "\n",
        "<body class=\"bg-light\">\n",
        "<div class=\"container py-5\">\n",
        "\n",
        "    <h2 class=\"mb-4 text-center\">Breast Ultrasound Classifier</h2>\n",
        "\n",
        "    <div class=\"card shadow-sm\">\n",
        "        <div class=\"card-body\">\n",
        "\n",
        "            <p>Upload an ultrasound image. The model will return a predicted class and confidence score.</p>\n",
        "\n",
        "            <form method=\"POST\" action=\"/predict\" enctype=\"multipart/form-data\">\n",
        "                <input type=\"file\" class=\"form-control mb-3\" name=\"file\" required>\n",
        "                <button class=\"btn btn-primary w-100\">Upload & Predict</button>\n",
        "            </form>\n",
        "\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    {% if result %}\n",
        "    <div class=\"alert alert-info mt-4\">\n",
        "        <strong>Prediction:</strong> {{ result.class }}\n",
        "        <br>\n",
        "        <strong>Confidence:</strong> {{ (result.confidence * 100) | round(2) }}%\n",
        "    </div>\n",
        "    {% endif %}\n",
        "\n",
        "</div>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j68RaI873r09",
        "outputId": "855763c4-cb99-449d-a609-43d839a17a96"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting templates/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, render_template, request\n",
        "import json\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    f = request.files[\"file\"]\n",
        "    # Dummy output for demo — replace with your ML model\n",
        "    result = {\"class\": \"benign\", \"confidence\": 0.80}\n",
        "    return render_template(\"index.html\", result=result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jkfuzXjA3vco",
        "outputId": "314aa3d9-caed-484d-8bec-9577d7deb7bc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — kill old server & start new Flask server\n",
        "!pkill -f \"python.*app.py\" || true\n",
        "!pkill -f flask || true\n",
        "\n",
        "!nohup python3 /content/ultrasound_project/app.py > /content/flask.log 2>&1 &\n",
        "\n",
        "!sleep 2\n",
        "!echo \"Flask server started. Checking logs...\"\n",
        "!tail -n 20 /content/flask.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FeCKM9gR16AA",
        "outputId": "f95c2cd5-f19a-4bd6-c27d-5688aa3c8d56"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n",
            "Flask server started. Checking logs...\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — clean ngrok start\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()   # stop all previous tunnels\n",
        "\n",
        "public_url = ngrok.connect(5000, \"http\")\n",
        "public_url\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6SMTVx971-af",
        "outputId": "8ccec1a8-3f5f-48ef-a3f5-5a7ce1519f07"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://subaquatic-wittingly-sharon.ngrok-free.dev\" -> \"http://localhost:5000\">"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}